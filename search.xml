<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>写代码避坑指南【1】java_集合</title>
      <link href="/2021/08/03/%E5%86%99%E4%BB%A3%E7%A0%81%E9%81%BF%E5%9D%91%E6%8C%87%E5%8D%97/%E5%86%99%E4%BB%A3%E7%A0%81%E9%81%BF%E5%9D%91%E6%8C%87%E5%8D%97%E3%80%901%E3%80%91java_%E9%9B%86%E5%90%88/"/>
      <url>/2021/08/03/%E5%86%99%E4%BB%A3%E7%A0%81%E9%81%BF%E5%9D%91%E6%8C%87%E5%8D%97/%E5%86%99%E4%BB%A3%E7%A0%81%E9%81%BF%E5%9D%91%E6%8C%87%E5%8D%97%E3%80%901%E3%80%91java_%E9%9B%86%E5%90%88/</url>
      
        <content type="html"><![CDATA[<p>java集合类，避坑指南。背了这么原理和实现，你真的能用对么？远离八股文工程师！</p><span id="more"></span><hr><h2><span id="写java避坑指南1有关collect包"> 写java避坑指南【1】有关collect包</span></h2><h3><span id="map"> Map</span></h3><h4><span id="线程不安全"> 线程不安全</span></h4><ul><li><p>多线程中，使用线程不安全的容器，后果不仅仅是数据不对，还可能导致程序死循环。所以还是不能无脑使用现成不安全的容器。</p></li><li><p>HashMap，中规中矩，默认使用。</p></li><li><p>Treemap，实现了SortedMap，放入的Key必须实现<code>Comparable</code>接口，有key排序首选使用。</p></li><li><p>EnumMap，如果作为key的对象是enum类型，首选使用，效率很高。</p></li><li><p>web开发中也需要空的 Map。使用<code>Map&lt;K, V&gt; emptyMap()</code></p></li><li><p>LinkedHashMap，要求key按照，put顺序存储时使用。</p></li><li><p>IdentityHashMap，kv的查找关系不是equals，而是==。即java的地址查找，只有序列化框架可能会用到，业务开发一般用不到。</p></li></ul><h4><span id="线程安全"> 线程安全</span></h4><ul><li><p>concurrenthashmap，中规中矩，默认使用。</p></li><li><p>hashtable，当必须保证强一致性时使用。concurrenthashmap中的get、size 等方法没有用到锁，有可能获得旧的数据。</p></li><li><p>concurrentSkipListMap，超大数据量(万级别)时候使用，且存在大量增删改操作的时候使用，在高并发下，跳表性能表现反超 concurrenthashmap。（红黑树在并发情况下，删除和插入过程中有个平衡的过程，锁竞争度会升高几个级别）</p></li></ul><h3><span id="map的使用注意事项"> map的使用注意事项</span></h3><ul><li>强制，k一定使用字符串，不允许用对象。（和equals方法有关，不展开）</li><li>默认，kv都尽量不允许为null。并发容器，k一定不允许为null，可能报npe不说，主要是没有意义。</li></ul><table><thead><tr><th>集合类</th><th>key<br>是否为null</th><th>value<br>是否为null</th><th>是否线程安全</th></tr></thead><tbody><tr><td>HashMap</td><td>允许l</td><td>允许</td><td>否</td></tr><tr><td>TreeMap</td><td>不允许</td><td>允许</td><td>否</td></tr><tr><td>LinkedHashMap</td><td>允许</td><td>允许</td><td>否</td></tr><tr><td>EnumMap</td><td>不允许</td><td>允许</td><td>否</td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td>HashTable</td><td>不允许</td><td>不允许</td><td>是</td></tr><tr><td>ConcurrentHashMap</td><td>不允许</td><td>不允许</td><td>是</td></tr><tr><td>ConcurrentSkipListMap</td><td>不允许</td><td>不允许</td><td>是</td></tr></tbody></table><hr><h3><span id="list"> List</span></h3><h4><span id="线程不安全"> 线程不安全</span></h4><ul><li>默认情况下一律使用ArrayList</li><li>有去重需要，默认使用HashSet</li><li>去重 + 重新排序使用TreeSet。</li><li>web开发中经常需要空 List。使用 <code>Collections.emptyList();</code></li><li>LinkedList，随机读性能很烂，业务开发没有使用场景，不建议使用</li></ul><h4><span id="线程安全"> 线程安全</span></h4><ul><li>线程安全List，首选 <code>Colletcions.synchronizedList(new ArrayList&lt;&gt;());</code> 各方面都没有问题。</li><li>线程安全Set，JDK没有提供，可以使用hutool实现的 <a href="https://www.hutool.cn/docs/#/core/%E9%9B%86%E5%90%88%E7%B1%BB/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84HashSet-ConcurrentHashSet?id=%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84hashset-concurrenthashset">线程安全的HashSet-ConcurrentHashSet</a></li><li>线程安全的队列，使用hutool实现的，<a href="https://www.hutool.cn/docs/#/core/%E9%9B%86%E5%90%88%E7%B1%BB/%E6%9C%89%E7%95%8C%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97-BoundedPriorityQueue?id=%E6%9C%89%E7%95%8C%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97-boundedpriorityqueue">有界优先队列-BoundedPriorityQueue</a></li><li>DelayQueue 延时队列，一般情况下不会使用，非要使用，切记不能使用纳秒为单位。<br>（纳秒会让cpu负载上升几个数量将）</li><li>CopyOnWriteArrayList 并发版ArrayList，这个容器写成本非常高，一般没有使用场景，如需并发写，ArrayList加锁即可。</li></ul><h3><span id="list的使用注意事项"> List的使用注意事项</span></h3><table><thead><tr><th>集合类</th><th>value<br>是否为null</th><th>是否线程安全</th></tr></thead><tbody><tr><td>ArrayList</td><td>允许</td><td>否</td></tr><tr><td>HashSet</td><td>允许</td><td>否</td></tr><tr><td>TreeSet</td><td>不允许</td><td>否</td></tr><tr><td>LinkedList</td><td>允许</td><td>否</td></tr><tr><td></td><td></td><td></td></tr><tr><td>HashTable</td><td>允许</td><td>是</td></tr><tr><td>ConcurrentHashSet</td><td>允许</td><td>是</td></tr><tr><td>BoundedPriorityQueue</td><td>允许</td><td>是</td></tr><tr><td>DelayQueue</td><td>允许</td><td>是</td></tr><tr><td>CopyOnWriteArrayList</td><td>允许</td><td>是</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 写代码避坑指南 </category>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 实用开发小抄 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka【5】命令行工具</title>
      <link href="/2021/08/02/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F/kafka%E3%80%905%E3%80%91%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/"/>
      <url>/2021/08/02/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F/kafka%E3%80%905%E3%80%91%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><hr><h2><span id="命令行工具"> 命令行工具</span></h2><h3><span id="生产消息"> 生产消息</span></h3><p>生产消息使用 kafka-console-producer 脚本：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4</span><br></code></pre></div></td></tr></table></figure><h3><span id="消费消息"> 消费消息</span></h3><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=<span class="hljs-literal">false</span></span> <br></code></pre></div></td></tr></table></figure><h3><span id="测试生产者性能"> 测试生产者性能</span></h3><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1</span> <br><span class="hljs-meta"></span><br><span class="hljs-meta">#</span><span class="bash">返回值</span><br>linger.ms=2000 compression.type=lz4 2175479 records sent, 435095.8 records/sec (424.90 MB/sec), 131.1 ms avg latency, 681.0 ms max latency. 4190124 records sent, 838024.8 records/sec (818.38 MB/sec), 4.4 ms avg latency, 73.0 ms max latency. 10000000 records sent, 737463.126844 records/sec (720.18 MB/sec), 31.81 ms avg latency, 681.00 ms max latency, 4 ms 50th, 126 ms 95th, 604 ms 99th, 672 ms 99.9th.<br></code></pre></div></td></tr></table></figure><ul><li><p>上述命令， 向指定主题发送了 1 千万条消息，每条消息大小是 1KB，</p></li><li><p>上述输出，表明测试生产者生产的消息中，有 99% 消息的延时都在 604ms 以内。</p><p>你完全可以把这个数据当作这个生产者对外承诺的 SLA。</p></li></ul><h3><span id="测试消费者性能"> 测试消费者性能</span></h3><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic</span> <br><span class="hljs-meta">#</span><span class="bash">返回值</span><br>start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec 2019-06-26 15:24:18:138, 2019-06-26 15:24:23:805, 9765.6202, 1723.2434, 10000000, 1764602.0822, 16, 5651, 1728.1225, 1769598.3012<br></code></pre></div></td></tr></table></figure><h3><span id="查看topic消息总数"> 查看topic消息总数</span></h3><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">最早位移</span><br><span class="hljs-meta">$</span><span class="bash"> bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -2 --topic test-topic</span><br> <br>test-topic:0:0<br>test-topic:1:0<br><span class="hljs-meta"></span><br><span class="hljs-meta">#</span><span class="bash">最新位移</span><br><span class="hljs-meta">$</span><span class="bash"> bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -1 --topic test-topic</span><br> <br>test-topic:0:5500000<br>test-topic:1:5500000<br><br></code></pre></div></td></tr></table></figure><ul><li><p>消息总数 =  最早位移 + 最新位移</p></li><li><p>对于本例，test-topic 总的消息数为 5500000 + 5500000，等于 1100 万条。</p></li></ul><h3><span id="查询消费者组位移"> 查询消费者组位移</span></h3><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> bin/kafka-console-consumer-groups.sh --bootstrap-server kafka-host:port --describe --group test-group</span><br></code></pre></div></td></tr></table></figure><ul><li>CURRENT-OFFSET 表示该消费者当前消费的最新位移，</li><li>LOG-END-OFFSET 表示对应分区最新生产消息的位移，</li><li>LAG 列是两者的差值。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 消息系统 </category>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka【4】client端最佳实践</title>
      <link href="/2021/08/02/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F/kafka%E3%80%904%E3%80%91client%E7%AB%AF%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
      <url>/2021/08/02/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F/kafka%E3%80%904%E3%80%91client%E7%AB%AF%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><hr><h1><span id="kafka4client端最佳实践"> kafka【4】client端最佳实践</span></h1><h2><span id="生产者分区策略"> 生产者分区策略</span></h2><h3><span id="分区策略的意义"> 分区策略的意义</span></h3><ul><li><p>分区实际上是调优Kafka并行度的最小单元</p></li><li><p>所谓分区策略是决定生产者将消息发送到哪个分区的算法。</p></li><li><p>如果一个topic分区越多，理论上整个集群所能达到的吞吐量就越大。</p></li></ul><h3><span id="自带的分区策略"> 自带的分区策略</span></h3><h4><span id="轮询策略"> 轮询策略</span></h4><ul><li>能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略</li></ul><h4><span id="随机策略"> 随机策略</span></h4><ul><li>如果追求数据的均匀分布，还是使用轮询策略比较好，随机策略暂时没想到场景</li></ul><h4><span id="按照key分区-key-ordering-策略"> 按照key分区 Key-ordering 策略</span></h4><ul><li>一旦消息被定义了 Key，则使用 key-ordering 策略，同一个 Key 的所有消息都进入到相同的partition</li><li>kafka只能保证同partition下的消息处理都是有顺序的，partition间无法做到有序。</li><li>如果所有数据都用这一个key，会导致分区数据不平衡，降低吞吐量。所以建议使用区分度较大的值作为key。比如 uid，pid，不要使用 status、if_xxx等</li><li>没有找到一个区分度大的key，又要保持顺序，则不要使用kafka，rocketMq不错。</li></ul><h3><span id="自定义分区策略"> 自定义分区策略</span></h3><ul><li>编写生产者程序时，可以自定义分区策略接口</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">// org.apache.kafka.clients.producer.Partitioner </span><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">partition</span><span class="hljs-params">(String topic, Object key, <span class="hljs-keyword">byte</span>[] keyBytes, Object value, <span class="hljs-keyword">byte</span>[] valueBytes, Cluster cluster)</span></span><br><span class="hljs-function"></span><br><span class="hljs-function">List&lt;PartitionInfo&gt; partitions </span>= cluster.partitionsForTopic(topic); <br><span class="hljs-keyword">return</span> Math.abs(key.hashCode()) % partitions.size();<br><br></code></pre></div></td></tr></table></figure><h2><span id="producer-端配置实践"> producer 端配置实践</span></h2><h3><span id="生产者基本配置"> 生产者基本配置</span></h3><h4><span id="消息版本"> 消息版本</span></h4><p>Producer 和 Broker 的消息版本要统一（如果不统一，Broker要进行消息解析）</p><h4><span id="压缩"> 压缩</span></h4><ul><li>最好开启LZ4压缩。</li><li>压缩配置，Producer 端压缩、Broker 端保持、Consumer 端解压缩。</li></ul><h4><span id="提交策略"> 提交策略</span></h4><ul><li>设置 acks = master。代表master Broker 收到消息，消息就算“已提交”。</li><li>设置 acks = all。 代表所有副本Broker 都接收到消息，该消息才算是“已提交”。</li></ul><h4><span id="重试次数"> 重试次数</span></h4><p>设置 retries 为一个较大的值 比如3</p><h4><span id="提交的方法"> 提交的方法</span></h4><p>使用 producer.send(msg, callback)，必须实现回调函数。</p><h4><span id="幂等消息"> 幂等消息</span></h4><ul><li>幂等消息是 0.11.0.0 版本以后，引入的</li><li>开启方法：设置enable.idempotence=ture</li><li>注意事项：<ul><li>只能保证单分区上的幂等性，且当 Producer 进程重启以后之后，这种幂等性保证就丧失了</li><li>需要 <strong>多分区，多会话</strong>上的消息无重复，需要使用事务型Producer</li></ul></li></ul><h4><span id="事务型-producer"> 事务型 Producer</span></h4><ul><li><p>保证一批消息原子性地写入到多个分区中，这批消息要么全部写入成功，要么全部失败。</p></li><li><p><strong>开启方法</strong>：</p><ul><li><p>配置 enable.idempotence=ture</p></li><li><p>使用下面方法生产消息</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//发送代码</span><br>producer.initTransactions();<br><span class="hljs-keyword">try</span> &#123;<br>            producer.beginTransaction();<br>            producer.send(record1);<br>            producer.send(record2);<br>            producer.commitTransaction();<br>&#125; <span class="hljs-keyword">catch</span> (KafkaException e) &#123;<br>            producer.abortTransaction();<br>&#125;<br></code></pre></div></td></tr></table></figure></li><li><p><strong>需要注意</strong>，事务消息，在consumer端也要进行配置成 read_committed，表明 Consumer 只会消费 事务型 Producer 成功提交事务写入的消息。<br>Consumer 默认 read_uncommitted ， 表示消费者会消费所有消息，如果用了事务型 Producer，对应的 Consumer 就不要使用这个值，这是个坑。</p></li></ul></li></ul><h2><span id="消费者注意事项"> 消费者注意事项</span></h2><h3><span id="基本原则"> 基本原则</span></h3><ul><li><p>先实际消费，再提交位移。</p></li><li><p>默认先关闭自动提交 enable.auto.commit =  false ， 看场景选择是否打开。</p></li><li><p>必须配置消费者连接超时间， <a href="http://connection.max.idle.ms">connection.max.idle.ms</a></p></li><li><p>一个分区，只能被一个消费者消费。Consumer 实例的数量应该等于该 Group 订阅 Topic 的分区总数 。如果需要高可用，则 一个分区被两个消费者消费比较合理</p></li></ul><h3><span id="独立消费者组"> 独立消费者组</span></h3><ul><li><p>Kafka Java Consumer 提供了一个名为 Standalone Consumer 的独立消费者类型。它没有消费者组的概念，每个消费者实例都是独立工作的，彼此之间毫无联系。</p></li><li><p>独立消费者，仍然需要配置 <a href="http://group.id">group.id</a> 。且一旦独立消费者 与 <a href="http://xn--group-3h2hx0n.id">其他group.id</a> 重名，当独立消费者提交位移时，Kafka 就会立即抛出 CommitFailedException 异常，这已是一个坑，<a href="http://xn--group-338lt35b.id">管理group.id</a> 也是必要的。</p></li></ul><h3><span id="提交"> 提交</span></h3><h4><span id="自动提交"> 自动提交</span></h4><ul><li><p>尽量不要使用，除非数据丢失无所谓，比如坐标点数据。</p></li><li><p>enable.auto.commit = true 。 开启自动提交。</p></li><li><p>auto.commit.interval.ms=5 。表明 Kafka 每 5 秒会为你自动提交一次位移</p></li></ul><h4><span id="手动提交范例"> 手动提交范例</span></h4><ul><li><p>同步提交带重试功能 ，如果不需要高吞吐量，可以利用 commitSync 的自动重试来规避那些瞬时错误，比如网络的瞬时抖动</p></li><li><p>提交模板</p></li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">try</span> &#123;<br>    <span class="hljs-keyword">while</span> (<span class="hljs-keyword">true</span>) &#123;<br>        ConsumerRecords&lt;String, String&gt; records = <br>            consumer.poll(Duration.ofSeconds(<span class="hljs-number">1</span>));<br>        process(records); <span class="hljs-comment">// 处理消息</span><br>        commitAysnc(); <span class="hljs-comment">// 使用异步提交规避阻塞</span><br>    &#125;<br>&#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>    handle(e); <span class="hljs-comment">// 处理异常</span><br>&#125; <span class="hljs-keyword">finally</span> &#123;<br>    <span class="hljs-keyword">try</span> &#123;<br>        consumer.commitSync(); <span class="hljs-comment">// 最后一次提交使用同步阻塞式提交</span><br>    &#125; <span class="hljs-keyword">finally</span> &#123;<br>        consumer.close();<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h4><span id="精细管理位移"> 精细管理位移</span></h4><ul><li>Kafka Consumer API 还提供了一组更为方便的方法，可以帮助你实现更精细化的位移管理功能。</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java">commitSync(Map&lt;TopicPartition, OffsetAndMetadata&gt;) <br>commitAsync(Map&lt;TopicPartition, OffsetAndMetadata&gt;)<br><br><span class="hljs-keyword">private</span> Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();<br><span class="hljs-keyword">int</span> count = <span class="hljs-number">0</span>;<br>……<br>……  <br><span class="hljs-keyword">while</span> (<span class="hljs-keyword">true</span>) &#123;<br>    ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class="hljs-number">1</span>));<br>    <span class="hljs-keyword">for</span> (ConsumerRecord&lt;String, String&gt; record: records) &#123;<br>        process(record);  <span class="hljs-comment">// 处理消息</span><br>        offsets.put(<span class="hljs-keyword">new</span> TopicPartition(record.topic(), record.partition()),<br>                    <span class="hljs-keyword">new</span> OffsetAndMetadata(record.offset() + <span class="hljs-number">1</span>); <br>        <span class="hljs-keyword">if</span>（count % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>）&#123;<br>            consumer.commitAsync(offsets, <span class="hljs-keyword">null</span>); <span class="hljs-comment">// 回调处理逻辑是 null</span><br>        &#125;<br>                    <br>        count++;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h3><span id="防止不必要rebalance"> <strong>防止不必要rebalance</strong></span></h3><p>消费者重平衡，是我们最经常遇到的问题。这里罗列一下常见的原因，尽量避免。</p><ul><li><p><strong>心跳超时</strong>会导致 Consumer 被 “踢出” Group</p></li><li><p><strong>消费时间过长</strong> 会导致 Consumer 被 “踢出” Group</p></li><li><p><strong>频繁的 Full GC 导致的长时间停顿</strong>，引发了 Rebalance，这个在高吞吐量的时候，也比较很常见。<br>需要联合gc情况一起排查。</p></li><li><p><strong>总结</strong>：</p><ul><li><p><a href="http://session.timeout.ms">session.timeout.ms</a> = 7s</p><p><a href="http://heartbeat.interval.ms">heartbeat.interval.ms</a> = 2s。</p><p>解释：要保证 Consumer 实例在被判定为“dead”之前，能够发送至少 3 轮的心跳请求，即 <a href="http://session.timeout.ms">session.timeout.ms</a> &gt;= 3 * <a href="http://heartbeat.interval.ms">heartbeat.interval.ms</a>。</p></li><li><p>设置 <a href="http://max.poll.interval.ms">max.poll.interval.ms</a>  消费时长，根据业务的消费速度，预留充足的超时时间。</p></li></ul></li></ul><h2><span id="消费者最佳实践"> 消费者最佳实践</span></h2><h3><span id="消费者原则"> 消费者原则</span></h3><ol><li>缩短单条消息处理的时间。</li><li>减少下游系统一次性消费的消息总数。</li><li>消费系统使用多线程来加速消费。（<strong>最好方法</strong>）</li><li>KafkaConsumer 类线程不安全，在多个线程中共享时，会抛 ConcurrentModificationException</li><li>消费者启动多线程，n个Consumer对应n个线程，根据业务模式选择同步消费还是异步消费。</li></ol><p><strong>选型</strong></p><ul><li>方案一：多consumer + 相同线程消费。</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">KafkaConsumerRunner</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Runnable</span> </span>&#123;<br>     <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> AtomicBoolean closed = <span class="hljs-keyword">new</span> AtomicBoolean(<span class="hljs-keyword">false</span>);<br>     <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> KafkaConsumer consumer;<br> <br>     <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">run</span><span class="hljs-params">()</span> </span>&#123;<br>         <span class="hljs-keyword">try</span> &#123;<br>             consumer.subscribe(Arrays.asList(<span class="hljs-string">&quot;topic&quot;</span>));<br>             <span class="hljs-keyword">while</span> (!closed.get()) &#123;<br>ConsumerRecords records = <br>consumer.poll(Duration.ofMillis(<span class="hljs-number">10000</span>));<br>                 <span class="hljs-comment">//  执行消息处理逻辑</span><br>             &#125;<br>         &#125; <span class="hljs-keyword">catch</span> (WakeupException e) &#123;<br>             <span class="hljs-comment">// Ignore exception if closing</span><br>             <span class="hljs-keyword">if</span> (!closed.get()) <span class="hljs-keyword">throw</span> e;<br>         &#125; <span class="hljs-keyword">finally</span> &#123;<br>             consumer.close();<br>         &#125;<br>     &#125;<br> <br>     <span class="hljs-comment">// Shutdown hook which can be called from a separate thread</span><br>     <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">shutdown</span><span class="hljs-params">()</span> </span>&#123;<br>         closed.set(<span class="hljs-keyword">true</span>);<br>         consumer.wakeup();<br>     &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><ul><li>方案二：单consumer + 多线程消费。</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> KafkaConsumer&lt;String, String&gt; consumer;<br><span class="hljs-keyword">private</span> ExecutorService executors;<br>...<br> <br><span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> workerNum = ...;<br>executors = <span class="hljs-keyword">new</span> ThreadPoolExecutor(<br>workerNum, workerNum, <span class="hljs-number">0L</span>, TimeUnit.MILLISECONDS,<br><span class="hljs-keyword">new</span> ArrayBlockingQueue&lt;&gt;(<span class="hljs-number">1000</span>), <br><span class="hljs-keyword">new</span> ThreadPoolExecutor.CallerRunsPolicy());<br> <br> <br>...<br><span class="hljs-keyword">while</span> (<span class="hljs-keyword">true</span>)  &#123;<br>ConsumerRecords&lt;String, String&gt; records = <br>consumer.poll(Duration.ofSeconds(<span class="hljs-number">1</span>));<br><span class="hljs-keyword">for</span> (<span class="hljs-keyword">final</span> ConsumerRecord record : records) &#123;<br>executors.submit(<span class="hljs-keyword">new</span> Worker(record));<br>&#125;<br>&#125;<br>..<br></code></pre></div></td></tr></table></figure><h2><span id="kafa拦截器"> kafa拦截器</span></h2><p>Kafka 拦截器最低版本是0.10.0.0 。</p><h3><span id="生产者拦截器"> 生产者拦截器</span></h3><h4><span id="实现方法"> 实现方法</span></h4><p><code>implement org.apache.kafka.clients.producer.ProducerInterceptor</code></p><p><a href="https://github.com/apache/kafka/blob/1a7ad70f24a1fa6b1640c2f768457324bbcda0df/clients/src/main/java/org/apache/kafka/clients/producer/ProducerInterceptor.java">https://github.com/apache/kafka/blob/1a7ad70f24a1fa6b1640c2f768457324bbcda0df/clients/src/main/java/org/apache/kafka/clients/producer/ProducerInterceptor.java</a></p><ul><li><p>onSend：该方法会在消息发送之前被调用。如果想在发送之前对消息“美美容”，可以使用此方法</p></li><li><p>onAcknowledgement：该方法会在消息成功提交或发送失败之后被调用。</p><p>onAcknowledgement 的调用要早于 callback 的调用。</p></li></ul><h4><span id="备注"> <strong>备注</strong>：</span></h4><ul><li>两个方法不是在同一个线程中被调用的，如果两个方法中调用了某个共享可变对象，要保证线程安全</li><li>不能阻塞，别放一些太重的逻辑进去，否则你会发现你的 Producer TPS 直线下降</li></ul><h3><span id="消费者拦截器"> 消费者拦截器</span></h3><h4><span id="实现方法"> 实现方法</span></h4><p><code>implement org.apache.kafka.clients.consumer.ConsumerInterceptor</code></p><p><a href="https://github.com/apache/kafka/blob/1a7ad70f24a1fa6b1640c2f768457324bbcda0df/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerInterceptor.java">https://github.com/apache/kafka/blob/1a7ad70f24a1fa6b1640c2f768457324bbcda0df/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerInterceptor.java</a></p><ul><li><p>onConsume：该方法在消息返回给 Consumer 程序之前调用。在开始正式处理消息之前，</p><p>拦截器会先拦一道，搞一些事情，之后再返回给你。</p></li><li><p>onCommit：Consumer 在提交位移之后调用该方法。通常在该方法中做一些审计类业务</p><p>比如打日志，统计等。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 消息系统 </category>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka【3】server端配置实践</title>
      <link href="/2021/08/02/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F/kafka%E3%80%903%E3%80%91server%E7%AB%AF%E9%85%8D%E7%BD%AE%E5%AE%9E%E8%B7%B5/"/>
      <url>/2021/08/02/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F/kafka%E3%80%903%E3%80%91server%E7%AB%AF%E9%85%8D%E7%BD%AE%E5%AE%9E%E8%B7%B5/</url>
      
        <content type="html"><![CDATA[<p>这是摘要</p><span id="more"></span><hr><h2><span id="broker-端参数"> <strong>Broker 端参数</strong></span></h2><h3><span id="基本配置"> 基本配置</span></h3><h4><span id="logdirs"> log.dirs</span></h4><ul><li>这是非常重要的参数，指定了 Broker 需要使用的若干个文件目录路径。</li><li>在线上生产环境中一定要为log.dirs配置多个路径，具体格式是一个 CSV格式，也就是用逗号分隔的多个路径，比如/home/kafka1,/home/kafka2,/home/kafka3</li><li>如果有条件的话你最好保证这些目录挂载到不同的物理磁盘上 多块物理磁盘同时读写数据有更高的吞吐量。 能够实现故障转移</li></ul><h3><span id="配置zookeeper"> 配置zookeeper</span></h3><h4><span id="zookeeperconnect"> zookeeper.connect</span></h4><ul><li>非常重要的参数，代表了zk的地址。</li><li>这也是一个 CSV 格式的参数，比 如我可以指定它的值为 zk1:2181,zk2:2181,zk3:2181。2181 是 ZooKeeper 的默认端口。</li><li>如果你有两套 Kafka 集群，假设分别叫它们 kafka1 和 kafka2，那么两套集群的zookeeper.connect参数可以这样指定:<ul><li>zk1:2181,zk2:2181,zk3:2181/kafka1和 zk1:2181,zk2:2181,zk3:2181/kafka2。</li><li>kafkaName 只需要写一次，而且是加到最后的。<br>反例 : zk1:2181/kafka1,zk2:2181/kafka2,zk3:2181/kafka3，这样的格式是不对的。</li></ul></li></ul><h3><span id="broker连接"> Broker连接</span></h3><h4><span id="compressiontype"> compression.type</span></h4><p>设置成producer，要按照生产者压缩格式来，防止 broker出现消息解压缩。</p><h4><span id="uncleanleaderelectionenable"> unclean.leader.election.enable</span></h4><p>unclean.leader.election.enable = false。 如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false</p><h4><span id="replicationfactor"> replication.factor</span></h4><p>replication.factor 配置要大于等于3。 最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余</p><h4><span id="mininsyncreplicas"> min.insync.replicas</span></h4><p>min.insync.replicas 至少要大于1。 本属性代表，消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。</p><p>确保 replication.factor &gt; min.insync.replicas。 推荐设置成 replication.factor = min.insync.replicas + 1。</p><h3><span id="topic管理"> Topic管理</span></h3><h4><span id="autocreatetopicsenable"> auto.create.topics.enable</span></h4><p>是否允许自动创建 Topic。建议否，由运维管理，要不然乱七八糟的topic满天飞。</p><h4><span id="uncleanleaderelectionenable"> unclean.leader.election.enable</span></h4><p>是否允许 Unclean Leader 选举。建议你还是显式地把它设置成 false</p><h4><span id="autoleaderrebalanceenable"> auto.leader.rebalance.enable</span></h4><p>是否允许定期进行 Leader 选举，建议在生产环境中把这个参数设置成 false，系统正常运行，没必要整活</p><h3><span id="数据留存"> 数据留存</span></h3><h4><span id="logretentionhourminutesms"> log.retention.{hour|minutes|ms}</span></h4><p>都是控制一条消息数据被保存多长时间，根据业务需求来。</p><h4><span id="logretentionbytes"> log.retention.bytes</span></h4><p>这是指定 Broker 为消息保存的总磁盘容量大小</p><h4><span id="messagemaxbytes"> message.max.bytes</span></h4><p>控制 Broker 能够接收的最大消息大小。<br>默认的 1000012 (1MB)太少了，因此在线上环境中设置一个比较大的值比较保险。根据业务情况来</p>]]></content>
      
      
      <categories>
          
          <category> 消息系统 </category>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka【2】版本&amp;部署规划</title>
      <link href="/2021/08/02/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F/kafka%E3%80%902%E3%80%91%E7%89%88%E6%9C%AC&amp;%E9%83%A8%E7%BD%B2%E8%A7%84%E5%88%92/"/>
      <url>/2021/08/02/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F/kafka%E3%80%902%E3%80%91%E7%89%88%E6%9C%AC&amp;%E9%83%A8%E7%BD%B2%E8%A7%84%E5%88%92/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><hr><h2><span id="版本选择"> 版本选择</span></h2><p>Kafka 目前总共演进了 7 个大版本，分别是 0.7、0.8、0.9、0.10、0.11、1.0 和 2.0</p><h3><span id="最低版本使用要求"> 最低版本使用要求：</span></h3><ul><li><p>（总体上不建议使用）</p></li><li><p>至少要选择 0.8.2.2 ，</p></li><li><p>使用 老版本 Producer API ，</p></li><li><p>老版本 Consumer API。</p></li></ul><h3><span id="09版本注意事项"> 0.9版本注意事项：</span></h3><ul><li><p>（总体上不建议使用）</p></li><li><p>必须使用 新版本Producer API ，老版本Consumer API</p></li><li><p>不要使用0.9版本中的 新版本Consumer API ，bug超多</p></li></ul><h3><span id="010版本注意事项"> 0.10版本注意事项：</span></h3><ul><li><p>如果使用的话，就用最优小版本 <strong>0.10.2.2</strong></p></li><li><p>0.10.2.2 版本起，使用 新版本 Producer API ，新版本 Consumer API</p></li><li><p>0.10.2.2 修复了一个可能导致 Producer 性能降低的 Bug， 基于性能的缘故你也应该升级到 0.10.2.2</p></li></ul><h3><span id="011版本注意事项"> 0.11版本注意事项：</span></h3><ul><li><p>如果使用的话，就用最优小版本 <strong>0.11.0.3</strong></p></li><li><p>0.11.0.3版本，引入了两个重量级的功能</p><ul><li>幂等性 Producer API 以及 事务 Transaction API</li><li>对 Kafka 消息格式做了重构。</li></ul></li></ul><h3><span id="10-20版本"> 1.0、2.0版本</span></h3><ul><li>主要增加的功能是流处理计算功能，</li><li>消息引擎方面，没什么变更。</li><li>如果不使用流处理功能，则不用升级。</li></ul><h3><span id="版本选择总结"> 版本选择总结：</span></h3><ul><li><p>无需流处理功能，则选择尽量将版本选为 0.11.0.3，这个版本的消息引擎功能已经非常完善了</p></li><li><p>不论你用的是哪个版本，都请尽量保持服务器端版本和客户端版本一致， 否则可能损失很多 Kafka 为你提供的性能优化收益</p></li></ul><h2><span id="部署方式"> 部署方式</span></h2><h3><span id="操作系统选择linux"> 操作系统选择linux</span></h3><ul><li>实际上 Kafka 客户端底层使用了 Java 的 selector，selector 在 Linux 上的实现机制是 epoll，而在 Windows 平台上的实现机制是select。因此在这一点上将 Kafka 部署在 Linux 上是有优势的，因为能够获得更高效的 I/O 性能</li><li>在 Linux 部署 Kafka 能够享受到零拷贝技术所带来的 快速数据传输特性</li></ul><h3><span id="硬盘是否需要raid"> 硬盘是否需要RAID</span></h3><ul><li>kafka自带高可用策略，无需RAID，使用普通磁盘组成存储空间即可。 使用机械磁盘完全能够胜任 Kafka 线上环境。</li></ul><h3><span id="硬盘容量规划"> 硬盘容量规划</span></h3><ul><li>规划磁盘容量时你需要考虑下面这几个元素<ul><li>新增消息数</li><li>消息留存时间</li><li>平均消息大小</li><li>备份数</li><li>是否启用压缩</li></ul></li><li>其实，硬盘不是瓶颈，给足就好。带宽才是。</li></ul><h3><span id="带宽计算公式"> 带宽计算公式</span></h3><ul><li><p>带宽资源不足导致 Kafka 出现性能问题的比例至少占 60% 以上</p></li><li><p>即单台服务器使用带宽 700Mb / 3 ≈ 240Mbps。 这里的其实是相当保守的，你可以结合你自己机器的使用情况酌情减少此值。</p></li><li><p>举例：<br></p><p>1小时处理1TB为目标。 根据这个目标，我们每秒需要处理 2336Mb 的数据，除以 240，约等于 10 台服务器。 如果消息还需要额外复制两份，那么总的服务器台数还要乘以 3，即 30 台</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 消息系统 </category>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka【1】概述</title>
      <link href="/2021/08/02/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F/kafka%E3%80%901%E3%80%91%E6%A6%82%E8%BF%B0/"/>
      <url>/2021/08/02/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F/kafka%E3%80%901%E3%80%91%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><hr><h1><span id="kafka1概述"> kafka【1】概述</span></h1><h2><span id="消息队列的两种模式"> 消息队列的两种模式</span></h2><h3><span id="点对点模式-一对一"> 点对点模式 (一对一)</span></h3><ul><li>消费者主动拉取数据消息，消息拉取后，queue 中不再存储。</li><li>支持存在多个消费者，但是一个消息只能有一个消费者可以消费</li></ul><h3><span id="发布订阅模式-pubsub"> 发布/订阅模式 (Pub/Sub)</span></h3><ul><li>消费者拉取数据后不会立即清除信息，但是保留是有期限的</li><li>消息provider将消息发布到 Topic 中，同时有多个consumer订阅消息。 发布到 Topic 的消息会被所有订阅者消费</li><li>发布/订阅模式的队列又分为<ul><li>消费者主动 pull (Kafka)</li><li>broker 主动 push</li></ul></li></ul><p><img src="https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210802121218.png" alt="kafak机构图"></p>]]></content>
      
      
      <categories>
          
          <category> 消息系统 </category>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mycat【6】一次mycat在线分库记录</title>
      <link href="/2021/08/01/mycat/mycat%E3%80%906%E3%80%91%E4%B8%80%E6%AC%A1mycat%E5%9C%A8%E7%BA%BF%E5%88%86%E5%BA%93%E8%AE%B0%E5%BD%95/"/>
      <url>/2021/08/01/mycat/mycat%E3%80%906%E3%80%91%E4%B8%80%E6%AC%A1mycat%E5%9C%A8%E7%BA%BF%E5%88%86%E5%BA%93%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<p>这是一次 使用mycat 不停机扩容的纪录片</p><span id="more"></span><hr><h1><span id="一次mycat在线分库记录"> 一次mycat在线分库记录</span></h1><h2><span id="分发服务分表方案"> 分发服务分表方案</span></h2><h3><span id="目标"> 目标：</span></h3><ol><li><p>（核心目标）解决分发服务的数据库性能问题；</p></li><li><p>（非核心目标） 输出相对通用的分库分表技术方案；</p></li><li><p>（非核心目标） 了解学习本地技术架构与业务实现方案；</p></li></ol><h3><span id="验收条件"> 验收条件：</span></h3><ol><li>（强约束） 控制表规模；</li><li>（强） 整体稳定可靠，出问题可监控可排查；</li><li>（弱） 方案及经验可推广到别的项目；</li></ol><h3><span id="下面有三个分表策略"> 下面有三个分表策略</span></h3><ol><li>根据日期（月份） 进行哈希，确定取模天数 tran_1  、trans_2 、 tran_3 等</li><li>根据近期时间范围，近n个月的在一张表里面， 其他的在另一个表里面。 trans_1(30天内数据),、trans_2(30天外的数据，1号冷库)、trans_2(30天外的数据，2号冷库)</li><li>按照日期进行枚举拆分，比如 trans_2019_01 、trans_2019_02 、trans_2019_01 等</li></ol><p>下面对比：</p><table><thead><tr><th>对比项</th><th>方案1</th><th>方案2</th><th>方案3</th></tr></thead><tbody><tr><td>拆分逻辑</td><td>日期取模（取模天数&gt;2）</td><td>近期、远期拆分<br>（热数据单独一个库，<br>冷数据进行日期范围分库）</td><td>日期范围拆分</td></tr><tr><td>数据平均程度</td><td>平均</td><td>不平均</td><td>平均</td></tr><tr><td>冷热数据隔离性</td><td>一般</td><td>好</td><td>好</td></tr><tr><td>清理热数据是否方便</td><td>不方便</td><td>方便</td><td>方便</td></tr><tr><td>清理冷数据是否方便</td><td>不方便</td><td>方便</td><td>方便</td></tr><tr><td>随着数据规模<br>后续是否需要扩容</td><td>需要</td><td>几乎不需要</td><td>不需要</td></tr><tr><td>优点</td><td>通用套路</td><td>冷热数据分离性强，<br>在冷数据数据查询极少的情况下，<br>可以有效降低负载</td><td>隔离性强<br></td></tr><tr><td>缺点</td><td>无法做到冷热数据分离</td><td>操作简单，维护容易<br>但要解决冷热数据的迁移问题</td><td>需要滚动建表，维护起来麻烦</td></tr></tbody></table><h4><span id="方案选型总结"> 方案选型总结：</span></h4><ul><li>方案一：取模法，通用，简单。</li><li>方案二：可以冷热分离，但需要解决数据迁移问题</li><li>方案三：拆分粒度细，需要提前建表</li></ul><p>最终选择，取模法。</p><h4><span id="实施步骤记录"> 实施步骤记录：</span></h4><ol><li><p>分发服务，目前没有日期枚举字段，下一个迭代：</p><ol><li>需要加上日期的枚举字段。并修改 select 语句 ，update by id 的时候 加上 日期条件。（评估业务可行性）</li><li>实现双写，单读 （读写trans，写trans_side）</li><li>进行mycat 配置。</li><li>开始数据拷贝作业，使用data-x 同步数据，将旧数据拷贝至新的两个子库。</li></ol></li><li><p>迭代 app-&gt;app_v2，读写旧库，写新库。</p></li><li><p>观察mycat 写入双写数据的情况，尤其是看双写，是否会带来数据不一致，比如旧库成功，新库失败</p></li><li><p>迭代 mycat -&gt; mycat_v3 ，将 trans_side，和trans 改名，app_v2的数据源就无需改变</p></li><li><p>观察读取情况，开是否有数据不一致产生</p></li><li><p>迭代app -&gt; app_v3，此时将 trans_side 数据源的旁写逻辑去除即可。</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801170823.png" alt="步骤2，迭代app"></p><p><img src="https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801170841.png" alt="步骤4，迭代mycat"></p><p><img src="https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801170851.png" alt="步骤6，迭代app"></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mycat </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分库分表 </tag>
            
            <tag> 中间件 </tag>
            
            <tag> mycat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mycat【5】使用技巧</title>
      <link href="/2021/08/01/mycat/mycat%E3%80%905%E3%80%91%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/"/>
      <url>/2021/08/01/mycat/mycat%E3%80%905%E3%80%91%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/</url>
      
        <content type="html"><![CDATA[<p>mycat一些常见的使用技巧，和特殊sql语句</p><span id="more"></span><hr><h1><span id="mycat-使用技巧"> mycat 使用技巧</span></h1><h2><span id="mycat-限制"> mycat 限制</span></h2><p><strong>mycat 不适用的场景</strong></p><ol><li>需要大量使用，mycat禁用sql语句的场景</li><li>经常需要跨分片关联查询的场景，ER分区表，全局表都不合适的时候。</li><li>必须保证跨分片事物的强一致性的时候。</li></ol><p><strong>mycat 不支持的sql语句</strong></p><ol><li><p><code>create table like XXX / create table select XXX</code></p></li><li><p>跨库（跨分片）多表关联查询，子查询</p></li><li><p><code>select for update / select lock in share mode</code> ，</p><p>悲观锁只会锁住一个数据节点，其他数据节点不加锁；并且加锁的时候，也不会抛出异常。</p><p>可能会产生数据不一致。</p></li><li><p>多表 update 更新 、update 分片键。update 分片键后可能会导致后面的查询找不到数据。</p></li><li><p>跨分片update 、delete [order by] limit 。 mycat会在多个节点执行 limit语句，会造成数据删多了。</p></li></ol><p><strong>mycat 的弱分布式事务</strong></p><p>使用的XA方式提交，但当所有事物ready之后，发送commit，此时有一个节点commit失败，则其他节点不会回滚。</p><p>所以 mycat 的XA事物只能支持到 ready 操作之前。</p><p>这种情况很难出现。</p><h2><span id="mycat系统配置优化"> mycat系统配置优化</span></h2><h3><span id="jvm参数优化"> jvm参数优化</span></h3><p>配置 /bin/startup_nowrap.sh</p><h3><span id="serverxml-系统参数优化"> server.xml 系统参数优化</span></h3><table><thead><tr><th>值</th><th>解释</th><th>推荐值</th></tr></thead><tbody><tr><td>frontWriteQueueSize</td><td>指定前端写队列的大小</td><td>2048</td></tr><tr><td>processors</td><td>系统可用线程的数量</td><td>根据cpu压力，一般是cpu数量*4</td></tr><tr><td>processorBufferPool</td><td>指定所使用的ByteBuffer池的总字节容量，<br>单位为字节</td><td>2097152B</td></tr><tr><td>processorBufferChunk</td><td>指定所使用的单个ByteBuffer的容量，<br>单位为字节</td><td>4096B</td></tr><tr><td>processorExecutor</td><td>每个processor的线程池大小</td><td>16-64</td></tr></tbody></table><h4><span id="log4j2xml-日志级别优化"> log4j2.xml 日志级别优化</span></h4><p>修改日志级别就好，其他不用动</p><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">asyncRoot</span> <span class="hljs-attr">level</span>=<span class="hljs-string">&quot;info&quot;</span> <span class="hljs-attr">includeLocation</span>=<span class="hljs-string">&quot;true&quot;</span>&gt;</span><br></code></pre></div></td></tr></table></figure><h2><span id="mycat-web性能监控工具"> mycat-web性能监控工具</span></h2><p>已经打好包，在dockerhub上。</p><figure class="highlight sh"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs sh">docker run --name mycat-web -d -p 8082:8082 --restart=always coolflame/mycat-web  <br></code></pre></div></td></tr></table></figure><p>访问地址：</p><p><a href="http://localhost:8082/mycat/">http://localhost:8082/mycat/</a></p><h2><span id="mycat常用sql语句"> mycat常用sql语句</span></h2><p>使用 <code>mysql -u[username] -p -P[管理端口，默认9066] -h[ip]</code>连接MyCat命令行管理端</p><figure class="highlight plaintext"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs mysql">-- 常用:<br># sql统计: 高频sql<br>show @@sql.high;<br># sql统计: 大返回值<br>show @@sql.resultset  ;<br># sql统计: 慢查询<br>show @@sql.slow  ;<br># 线程池状态<br>show @@threadpool ;<br><br>-- 不常用:<br>#连接信息<br>show @@connection <br>#后端库信息<br>show @@datasource;<br>#非堆内存使用情况<br>show @@directmemory=1;<br>#心跳情况<br>show @@heartbeat ;<br>#活动线程情况<br>show @@processor;<br>#mycat 服务器情况,主要是内存使用<br>show @@server;<br></code></pre></div></td></tr></table></figure><h2><span id="使用mycat生成执行sql记录"> 使用MyCat生成执行SQL记录</span></h2><p>在server.xml的system标签下配置拦截</p><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">system</span>&gt;</span><br>  <span class="hljs-comment">&lt;!-- 配置拦截器 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;sqlInterceptor&quot;</span>&gt;</span><br>    io.mycat.server.interceptor.impl.StatisticsSqlInterceptor<br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-comment">&lt;!-- 配置拦截SQL类型 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;sqlInterceptorType&quot;</span>&gt;</span><br>    select，update，insert，delete<br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-comment">&lt;!-- 配置SQL生成文件位置 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;sqlInterceptorFile&quot;</span>&gt;</span><br>    /opt/mycat/InterceptorFile/sql.txt<br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">system</span>&gt;</span><br></code></pre></div></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mycat </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分库分表 </tag>
            
            <tag> 中间件 </tag>
            
            <tag> mycat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mycat【3】高可用方案</title>
      <link href="/2021/08/01/mycat/mycat%E3%80%903%E3%80%91%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88/"/>
      <url>/2021/08/01/mycat/mycat%E3%80%903%E3%80%91%E9%AB%98%E5%8F%AF%E7%94%A8%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<p>这是摘要</p><span id="more"></span><hr><h1><span id="mycat高可用方案"> mycat高可用方案</span></h1><h2><span id="haproxy-mycat-zookeeper-mysql主从"> Haproxy + Mycat + zookeeper + Mysql主从</span></h2><h3><span id="架构图"> 架构图</span></h3><pre><code class=" mermaid">graph TDAPP1[APP] --&gt; Haproxy1[Haproxy] Haproxy1[Haproxy] --&gt; mycat1[Mycat] mycat1[Mycat] --&gt; 订单库01mycat1[Mycat] --&gt; 订单库02mycat1[Mycat] --&gt; 用户库mycat1[Mycat] --&gt; 商品库ZK[ZK] --&gt; mycat2ZK[ZK] --&gt; mycat1APP2[APP] --&gt; Haproxy2[Haproxy] Haproxy2[Haproxy] --&gt; mycat2[Mycat] mycat2[Mycat] --&gt; 订单库01mycat2[Mycat] --&gt; 订单库02mycat2[Mycat] --&gt; 用户库mycat2[Mycat] --&gt; 商品库订单库01 --&gt; 订单库01_slave订单库02 --&gt; 订单库02_slave用户库 --&gt; 用户库_slave商品库 --&gt; 商品库_slave</code></pre><h3><span id="实现步骤"> 实现步骤</span></h3><h4><span id="使用-zookeeper-管理-mycat-的配置文件"> 使用 zookeeper 管理 mycat 的配置文件</span></h4><p>（schema.xml、server.xml、rule.xml、sequence_db_conf.properties）</p><ol><li><p>将 mycat/conf 下的配置文件 ，schema.xml server.xml rule.xml sequence_db_conf.properties 复制到 mycat/conf/zkconf下</p></li><li><p>使用 bin/init_zk_data.sh 脚本 将mycat配置信息初始化到zk中。</p><p>配置信息存在于 zk 中的/mycat/mycat-cluster-1下面</p></li><li><p>配置mycat，使用zk模式启动，配置 myid.properties 中的内容</p><figure class="highlight properties"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs properties"><span class="hljs-attr">loadZK</span>=<span class="hljs-string">true</span><br><span class="hljs-attr">zkURL</span>=<span class="hljs-string">192.168.x.x，192.168.x.x，192.168.x.x，</span><br><span class="hljs-attr">clusterId</span>=<span class="hljs-string">mycat-cluster-1</span><br><span class="hljs-attr">myid</span>=<span class="hljs-string">mycat_01 [mycat集群中，本实例的id，该值不能重复]</span><br><span class="hljs-attr">clusterSize</span>=<span class="hljs-string">2 [有多少个mycat实例]</span><br><span class="hljs-attr">clusterNodes</span>=<span class="hljs-string">mycat_01,mycat_02 [全部的mycat实例id]</span><br></code></pre></div></td></tr></table></figure></li><li><p>使用 mycat start 重启mycat</p></li><li><p>后续维护配置信息，只要修改zk中的配置即可。可以使用 1，2步骤对zk中的配置进行修改</p></li></ol><h4><span id="使用-haproxy-实现-mycat的-lb-amp-ha"> <strong>使用 HAProxy 实现 mycat的 LB &amp; HA</strong></span></h4><ol><li>安装HAProxy，并使用 Keepalived 监控 HAProxy。</li><li>配置 HAProxy 监控 Mycat</li><li>配置应用通过 VIP 访问 HAProxy</li></ol><h4><span id="mycat-配置-mysql-主从读写分离"> <strong>mycat 配置 mysql 主从读写分离</strong></span></h4><ol><li><p>配置 mysql ，直线主从复制</p></li><li><p>配置 mycat 对后端db 进行读写分离，修改schema.xml 中的dataHost标签，新增一个readHost</p><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dataHost</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;userHost&quot;</span> <span class="hljs-attr">maxCon</span>=<span class="hljs-string">&quot;1000&quot;</span> <span class="hljs-attr">minCon</span>=<span class="hljs-string">&quot;10&quot;</span> <span class="hljs-attr">balance</span>=<span class="hljs-string">&quot;0&quot;</span> <span class="hljs-attr">writeType</span>=<span class="hljs-string">&quot;0&quot;</span> <span class="hljs-attr">dbType</span>=<span class="hljs-string">&quot;mysql&quot;</span> <span class="hljs-attr">dbDriver</span>=<span class="hljs-string">&quot;native&quot;</span> <span class="hljs-attr">switchType</span>=<span class="hljs-string">&quot;1&quot;</span>&gt;</span> <br>  <span class="hljs-tag">&lt;<span class="hljs-name">heartbeat</span>&gt;</span>select user()<span class="hljs-tag">&lt;/<span class="hljs-name">heartbeat</span>&gt;</span><br>  <span class="hljs-comment">&lt;!-- 主写，从读 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">writeHost</span> <span class="hljs-attr">host</span>=<span class="hljs-string">&quot;localhost&quot;</span> <span class="hljs-attr">url</span>=<span class="hljs-string">&quot;localhost:3306&quot;</span> <span class="hljs-attr">user</span>=<span class="hljs-string">&quot;user_db_user&quot;</span> <span class="hljs-attr">password</span>=<span class="hljs-string">&quot;123456&quot;</span> &gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">readHost</span> <span class="hljs-attr">host</span>=<span class="hljs-string">&quot;192.168.1.6&quot;</span> <span class="hljs-attr">url</span>=<span class="hljs-string">&quot;192.168.1.6:3306&quot;</span> <span class="hljs-attr">user</span>=<span class="hljs-string">&quot;user_db_user&quot;</span> <span class="hljs-attr">password</span>=<span class="hljs-string">&quot;123456&quot;</span>/&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">writeHost</span>&gt;</span><br>  <span class="hljs-comment">&lt;!-- 配置从库，读写。他可以保证主库挂掉的时候，读写操作都进入从库 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">writeHost</span> <span class="hljs-attr">host</span>=<span class="hljs-string">&quot;192.168.1.6&quot;</span> <span class="hljs-attr">url</span>=<span class="hljs-string">&quot;192.168.1.6:3306&quot;</span> <span class="hljs-attr">user</span>=<span class="hljs-string">&quot;user_db_user&quot;</span> <span class="hljs-attr">password</span>=<span class="hljs-string">&quot;123456&quot;</span> /&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dataHost</span>&gt;</span><br></code></pre></div></td></tr></table></figure></li><li><p>滚动重启mycat</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mycat </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分库分表 </tag>
            
            <tag> 中间件 </tag>
            
            <tag> mycat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mycat【2】分库配置实践</title>
      <link href="/2021/08/01/mycat/mycat%E3%80%902%E3%80%91%E5%88%86%E5%BA%93%E9%85%8D%E7%BD%AE%E5%AE%9E%E8%B7%B5/"/>
      <url>/2021/08/01/mycat/mycat%E3%80%902%E3%80%91%E5%88%86%E5%BA%93%E9%85%8D%E7%BD%AE%E5%AE%9E%E8%B7%B5/</url>
      
        <content type="html"><![CDATA[<p>本章主要讲了mycat 分库的配置，与实践套路</p><span id="more"></span><hr><h2><span id="mycat垂直切分"> mycat垂直切分</span></h2><h3><span id="垂直分库步骤"> 垂直分库步骤</span></h3><ol><li><h4><span id="分析数据库依赖关系"> 分析数据库依赖关系</span></h4><p>比如我们需要将订单表，用户表进行分库操作，master_db -&gt; order_db , master_db -&gt; user_db</p></li><li><h4><span id="配置主从复制"> 配置主从复制</span></h4><ol><li>备份原数据库并记录相关事务点（在主库中操作）</li></ol><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 数据导出，--master-data=2 --single-transaction 不能忘</span><br><span class="hljs-meta">$</span><span class="bash"> mysqldump --master-data=2 --single-transaction --routines --trigger --events -uroot -pxxxx master_db.sql &gt; sub_master_db.sql</span><br><span class="hljs-meta"></span><br><span class="hljs-meta">#</span><span class="bash"> 数据导入</span><br><span class="hljs-meta">$</span><span class="bash"> mysql -uroot -pxxxx order_db &lt; sub_master_db.sql</span><br><br></code></pre></div></td></tr></table></figure><ol start="2"><li>新建复制用户（在主库中操作，）</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs mysql">create user &#x27;trans_user&#x27;@&#x27;192.168.1.%&#x27; identified by &#x27;[passward]&#x27; ;<br><br>grant replication slave on *.* to &#x27;trans_user&#x27;@&#x27;192.168.1.%&#x27;;<br></code></pre></div></td></tr></table></figure><ol start="3"><li>在从库实例上恢复备份数据，并配置binlog 链路。</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs mysql"># 在从库中的配置主库地址<br>change master to master_host =&#x27;192.168.1.x&#x27; , <br>master_user = &#x27;trans_user&#x27; , <br>master_password = &#x27;xxx&#x27; , <br>master_log_file = &#x27;[开始同步的日志文件名，这个值在备份文件中，MASTER_LOG_FILE = &#x27;xxx&#x27;]&#x27; ,<br>master_log_pos = &#x27;[开始同步的事务点，这个值在备份文件中，MASTER_LOG_POS = &#x27;xxx&#x27;]&#x27; ;<br><br># 改写从库同步数据的数据库名称，主库中 master_db 在从库中则需要改写为 order_db <br># 使用主从复制中的过滤函数 RELICATE_REWRITE<br>filter replicate_rewrite_db = ((master_db,order_db))<br><br># 查询从库状态<br>show slave status<br># 启动复制链路<br>start slave<br><br># Slave_IO_Running, Slave_SQL_Running 状态为YES，则代表成功<br></code></pre></div></td></tr></table></figure></li><li><h4><span id="配置垂直分库逻辑"> 配置垂直分库逻辑</span></h4><p>通过中间件访问DB（垂直切分不需要配置 rule.xml）</p><ol><li>假如主库需要分2个库，一个是order库，一个是user库。</li><li>配置 schema.xml ，配置顺序为：dataHost(2个) -&gt; dataNode(2个) -&gt; schema(1个)</li></ol><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="hljs-meta">&lt;!DOCTYPE <span class="hljs-meta-keyword">mycat</span>:schema <span class="hljs-meta-keyword">SYSTEM</span> <span class="hljs-meta-string">&quot;schema.dtd&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">mycat:schema</span> <span class="hljs-attr">xmlns:mycat</span>=<span class="hljs-string">&quot;http://io.mycat/&quot;</span>&gt;</span><br>       <br>    <span class="hljs-comment">&lt;!-- ③ 配置逻辑数据库中， table 与dataNode间关系--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">schema</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;mall_db&quot;</span> <span class="hljs-attr">checkSQLschema</span>=<span class="hljs-string">&quot;true&quot;</span> <span class="hljs-attr">sqlMaxLimit</span>=<span class="hljs-string">&quot;100&quot;</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">table</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;order_detail&quot;</span> <span class="hljs-attr">primarykey</span>=<span class="hljs-string">&quot;id&quot;</span> <span class="hljs-attr">dataNode</span>=<span class="hljs-string">&quot;orderNode&quot;</span> &gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">table</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">table</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;order_account&quot;</span> <span class="hljs-attr">primarykey</span>=<span class="hljs-string">&quot;id&quot;</span> <span class="hljs-attr">dataNode</span>=<span class="hljs-string">&quot;orderNode&quot;</span> &gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">table</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">table</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;order_img&quot;</span> <span class="hljs-attr">primarykey</span>=<span class="hljs-string">&quot;id&quot;</span> <span class="hljs-attr">dataNode</span>=<span class="hljs-string">&quot;orderNode&quot;</span> &gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">table</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">table</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;user_address&quot;</span> <span class="hljs-attr">primarykey</span>=<span class="hljs-string">&quot;id&quot;</span> <span class="hljs-attr">dataNode</span>=<span class="hljs-string">&quot;userNode&quot;</span> &gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">table</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">table</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;user_info&quot;</span> <span class="hljs-attr">primarykey</span>=<span class="hljs-string">&quot;id&quot;</span> <span class="hljs-attr">dataNode</span>=<span class="hljs-string">&quot;userNode&quot;</span> &gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">table</span>&gt;</span><br>      <span class="hljs-comment">&lt;!-- 全局表，该表在所有的从库中都会有--&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">table</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;address&quot;</span> <span class="hljs-attr">primarykey</span>=<span class="hljs-string">&quot;id&quot;</span> <span class="hljs-attr">dataNode</span>=<span class="hljs-string">&quot;userNode,orderNode&quot;</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;global&quot;</span> &gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">table</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">schema</span>&gt;</span><br>   <br>    <span class="hljs-comment">&lt;!-- ② dataNode 数据库实例，与mysql实例映射--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dataNode</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;orderNode&quot;</span> <span class="hljs-attr">dataHost</span>=<span class="hljs-string">&quot;orderHost&quot;</span> <span class="hljs-attr">database</span>=<span class="hljs-string">&quot;order_db&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dataNode</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;userNode&quot;</span> <span class="hljs-attr">dataHost</span>=<span class="hljs-string">&quot;userHost&quot;</span> <span class="hljs-attr">database</span>=<span class="hljs-string">&quot;user_db&quot;</span> /&gt;</span><br>    <br>    <span class="hljs-comment">&lt;!-- ① dataHost mysql实例--&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">dataHost</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;orderHost&quot;</span> <span class="hljs-attr">maxCon</span>=<span class="hljs-string">&quot;1000&quot;</span> <span class="hljs-attr">minCon</span>=<span class="hljs-string">&quot;10&quot;</span> <span class="hljs-attr">balance</span>=<span class="hljs-string">&quot;0&quot;</span> <span class="hljs-attr">writeType</span>=<span class="hljs-string">&quot;0&quot;</span> <span class="hljs-attr">dbType</span>=<span class="hljs-string">&quot;mysql&quot;</span> <span class="hljs-attr">dbDriver</span>=<span class="hljs-string">&quot;native&quot;</span> <span class="hljs-attr">switchType</span>=<span class="hljs-string">&quot;1&quot;</span>&gt;</span> <br>      <span class="hljs-tag">&lt;<span class="hljs-name">heartbeat</span>&gt;</span>select user()<span class="hljs-tag">&lt;/<span class="hljs-name">heartbeat</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">writeHost</span> <span class="hljs-attr">host</span>=<span class="hljs-string">&quot;localhost&quot;</span> <span class="hljs-attr">url</span>=<span class="hljs-string">&quot;localhost:3307&quot;</span> <span class="hljs-attr">user</span>=<span class="hljs-string">&quot;order_db_user&quot;</span> <span class="hljs-attr">password</span>=<span class="hljs-string">&quot;123456&quot;</span> /&gt;</span> <br><span class="hljs-tag">&lt;/<span class="hljs-name">dataHost</span>&gt;</span><br>  <br>  <span class="hljs-tag">&lt;<span class="hljs-name">dataHost</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;userHost&quot;</span> <span class="hljs-attr">maxCon</span>=<span class="hljs-string">&quot;1000&quot;</span> <span class="hljs-attr">minCon</span>=<span class="hljs-string">&quot;10&quot;</span> <span class="hljs-attr">balance</span>=<span class="hljs-string">&quot;0&quot;</span> <span class="hljs-attr">writeType</span>=<span class="hljs-string">&quot;0&quot;</span> <span class="hljs-attr">dbType</span>=<span class="hljs-string">&quot;mysql&quot;</span> <span class="hljs-attr">dbDriver</span>=<span class="hljs-string">&quot;native&quot;</span> <span class="hljs-attr">switchType</span>=<span class="hljs-string">&quot;1&quot;</span>&gt;</span> <br>      <span class="hljs-tag">&lt;<span class="hljs-name">heartbeat</span>&gt;</span>select user()<span class="hljs-tag">&lt;/<span class="hljs-name">heartbeat</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">writeHost</span> <span class="hljs-attr">host</span>=<span class="hljs-string">&quot;localhost&quot;</span> <span class="hljs-attr">url</span>=<span class="hljs-string">&quot;localhost:3307&quot;</span> <span class="hljs-attr">user</span>=<span class="hljs-string">&quot;user_db_user&quot;</span> <span class="hljs-attr">password</span>=<span class="hljs-string">&quot;123456&quot;</span> /&gt;</span> <br><span class="hljs-tag">&lt;/<span class="hljs-name">dataHost</span>&gt;</span><br>    <br><span class="hljs-tag">&lt;/<span class="hljs-name">mycat:schema</span>&gt;</span><br></code></pre></div></td></tr></table></figure><ol start="2"><li>配置 server.xml 配置系统遍历及用户权限</li></ol><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">user</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;mall_user&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;password&quot;</span>&gt;</span>123456<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;schemas&quot;</span>&gt;</span>mall_db<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">user</span>&gt;</span><br></code></pre></div></td></tr></table></figure></li><li><h4><span id="开始作案"> 开始作案</span></h4><p>万事俱备后，夜黑风高之夜进行切换操作，需要预留足够的作案时间，回滚时间</p></li><li><h4><span id="收尾"> 收尾</span></h4><p>删除原库中，的已迁移数据。从库中，多余的数据。</p><ol><li>停止主从同步，stop slave;  reset slave all;  show status\g;</li><li>备份 ，drop表</li></ol></li></ol><h2><span id="水平切分"> 水平切分</span></h2><h3><span id="原则"> 原则：</span></h3><ol><li>能不切分就不切分。对于日志，历史记录这种大表，可以使用历史数据归档的方式进行数据转移，保证热点数据在数据库中即可。无法归档的数据时才考虑进行水平切分。</li><li>选择合适的分片字段及分配规则，一定要提前想好，因为查询的时候也尽量需要带上分片键，这个后期修改困难</li><li>尽量避免跨分片join</li></ol><h3><span id="步骤"> 步骤</span></h3><ol><li><h4><span id="确定分片键"> 确定分片键</span></h4><p>确定 分片表，分片键，分片算法，全局唯一id生成算法；记住要讨论一下有没有坑。</p><p><strong>分片表</strong>：将需要分片的表，以及频繁需要和分片表关联查询的表一起分片。（不经常使用join语句的话，可以忽略）</p><p><strong>分片键</strong>：主键id，业务唯一id（比如订单id），<strong>外键或namespace</strong>（比如订单关联的user_id,或者订单的日期, 订单的查询往往是以用户为单位查询，或者以时间为单位查询的，这一点需要考虑业务上的常用查询方式）</p><p><strong>分片算法</strong>：简单取模算法，哈希取模算法。</p></li><li><h4><span id="配置-mycat"> 配置 mycat</span></h4><p>schema.xml</p><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="hljs-meta">&lt;!DOCTYPE <span class="hljs-meta-keyword">mycat</span>:schema <span class="hljs-meta-keyword">SYSTEM</span> <span class="hljs-meta-string">&quot;schema.dtd&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">mycat:schema</span> <span class="hljs-attr">xmlns:mycat</span>=<span class="hljs-string">&quot;http://io.mycat/&quot;</span>&gt;</span><br>       <br>    <span class="hljs-comment">&lt;!-- ③ 配置逻辑数据库中， table 与dataNode间关系--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">schema</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;order&quot;</span> <span class="hljs-attr">checkSQLschema</span>=<span class="hljs-string">&quot;true&quot;</span> <span class="hljs-attr">sqlMaxLimit</span>=<span class="hljs-string">&quot;100&quot;</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">table</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;order_master&quot;</span> <span class="hljs-attr">primarykey</span>=<span class="hljs-string">&quot;id&quot;</span> <span class="hljs-attr">dataNode</span>=<span class="hljs-string">&quot;orderNode0101,orderNode0102,orderNode0203,orderNode0204&quot;</span> <span class="hljs-attr">rule</span>=<span class="hljs-string">&quot;order_master&quot;</span> &gt;</span><br>        <span class="hljs-comment">&lt;!-- ER分片表 --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">childTable</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;order_detail&quot;</span> <span class="hljs-attr">primaryKey</span>=<span class="hljs-string">&quot;id&quot;</span> <span class="hljs-attr">joinKey</span>=<span class="hljs-string">&quot;id&quot;</span> <span class="hljs-attr">parentKey</span>=<span class="hljs-string">&quot;id&quot;</span> /&gt;</span><br>        <br>      <span class="hljs-tag">&lt;/<span class="hljs-name">table</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">schema</span>&gt;</span><br>   <br>    <span class="hljs-comment">&lt;!-- ② dataNode 数据库实例，与mysql实例映射--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dataNode</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;orderNode0101&quot;</span> <span class="hljs-attr">dataHost</span>=<span class="hljs-string">&quot;orderHost01&quot;</span> <span class="hljs-attr">database</span>=<span class="hljs-string">&quot;order_db_01&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dataNode</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;orderNode0102&quot;</span> <span class="hljs-attr">dataHost</span>=<span class="hljs-string">&quot;orderHost01&quot;</span> <span class="hljs-attr">database</span>=<span class="hljs-string">&quot;order_db_02&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dataNode</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;orderNode0203&quot;</span> <span class="hljs-attr">dataHost</span>=<span class="hljs-string">&quot;orderHost02&quot;</span> <span class="hljs-attr">database</span>=<span class="hljs-string">&quot;order_db_03&quot;</span> /&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dataNode</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;orderNode0204&quot;</span> <span class="hljs-attr">dataHost</span>=<span class="hljs-string">&quot;orderHost02&quot;</span> <span class="hljs-attr">database</span>=<span class="hljs-string">&quot;order_db_04&quot;</span> /&gt;</span><br>    <br>    <span class="hljs-comment">&lt;!-- ① dataHost mysql实例--&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">dataHost</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;orderHost01&quot;</span> <span class="hljs-attr">maxCon</span>=<span class="hljs-string">&quot;1000&quot;</span> <span class="hljs-attr">minCon</span>=<span class="hljs-string">&quot;10&quot;</span> <span class="hljs-attr">balance</span>=<span class="hljs-string">&quot;0&quot;</span> <span class="hljs-attr">writeType</span>=<span class="hljs-string">&quot;0&quot;</span> <span class="hljs-attr">dbType</span>=<span class="hljs-string">&quot;mysql&quot;</span> <span class="hljs-attr">dbDriver</span>=<span class="hljs-string">&quot;native&quot;</span> <span class="hljs-attr">switchType</span>=<span class="hljs-string">&quot;1&quot;</span>&gt;</span> <br>      <span class="hljs-tag">&lt;<span class="hljs-name">heartbeat</span>&gt;</span>select user()<span class="hljs-tag">&lt;/<span class="hljs-name">heartbeat</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">writeHost</span> <span class="hljs-attr">host</span>=<span class="hljs-string">&quot;localhost&quot;</span> <span class="hljs-attr">url</span>=<span class="hljs-string">&quot;localhost:3307&quot;</span> <span class="hljs-attr">user</span>=<span class="hljs-string">&quot;order_db_user&quot;</span> <span class="hljs-attr">password</span>=<span class="hljs-string">&quot;123456&quot;</span> /&gt;</span> <br><span class="hljs-tag">&lt;/<span class="hljs-name">dataHost</span>&gt;</span><br>  <br>  <span class="hljs-tag">&lt;<span class="hljs-name">dataHost</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;orderHost02&quot;</span> <span class="hljs-attr">maxCon</span>=<span class="hljs-string">&quot;1000&quot;</span> <span class="hljs-attr">minCon</span>=<span class="hljs-string">&quot;10&quot;</span> <span class="hljs-attr">balance</span>=<span class="hljs-string">&quot;0&quot;</span> <span class="hljs-attr">writeType</span>=<span class="hljs-string">&quot;0&quot;</span> <span class="hljs-attr">dbType</span>=<span class="hljs-string">&quot;mysql&quot;</span> <span class="hljs-attr">dbDriver</span>=<span class="hljs-string">&quot;native&quot;</span> <span class="hljs-attr">switchType</span>=<span class="hljs-string">&quot;1&quot;</span>&gt;</span> <br>      <span class="hljs-tag">&lt;<span class="hljs-name">heartbeat</span>&gt;</span>select user()<span class="hljs-tag">&lt;/<span class="hljs-name">heartbeat</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">writeHost</span> <span class="hljs-attr">host</span>=<span class="hljs-string">&quot;localhost&quot;</span> <span class="hljs-attr">url</span>=<span class="hljs-string">&quot;localhost:3307&quot;</span> <span class="hljs-attr">user</span>=<span class="hljs-string">&quot;order_db_user&quot;</span> <span class="hljs-attr">password</span>=<span class="hljs-string">&quot;123456&quot;</span> /&gt;</span> <br><span class="hljs-tag">&lt;/<span class="hljs-name">dataHost</span>&gt;</span><br>    <br><span class="hljs-tag">&lt;/<span class="hljs-name">mycat:schema</span>&gt;</span><br></code></pre></div></td></tr></table></figure><p>rule.xml</p><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">mycat:rule</span> <span class="hljs-attr">xmlns:mycat</span>=<span class="hljs-string">&quot;http://io.mycat/&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">tableRule</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;order_mater&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">rule</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">columns</span>&gt;</span>user_id<span class="hljs-tag">&lt;/<span class="hljs-name">columns</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">algorithm</span>&gt;</span>mod-long<span class="hljs-tag">&lt;/<span class="hljs-name">algorithm</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">rule</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">tableRule</span>&gt;</span><br><br><span class="hljs-tag">&lt;<span class="hljs-name">function</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;mod-long&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;io.mycat.route.function.PartitionByMod&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;count&quot;</span>&gt;</span>4<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">function</span>&gt;</span><br>  <br><span class="hljs-tag">&lt;/<span class="hljs-name">mycat:rule</span>&gt;</span><br></code></pre></div></td></tr></table></figure><p>server.xml</p><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">user</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;mall_order&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;password&quot;</span>&gt;</span>123456<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;schemas&quot;</span>&gt;</span>order<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">user</span>&gt;</span><br></code></pre></div></td></tr></table></figure></li><li><p>数据迁移，使用脚本，按照规定的分片算法进行数据迁移即可。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mycat </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分库分表 </tag>
            
            <tag> 中间件 </tag>
            
            <tag> mycat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mycat【1】配置文件概述</title>
      <link href="/2021/08/01/mycat/mycat%E3%80%901%E3%80%91%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%A6%82%E8%BF%B0/"/>
      <url>/2021/08/01/mycat/mycat%E3%80%901%E3%80%91%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<p>这是摘要</p><span id="more"></span><hr><h1><span id="mycat配置文件概述"> mycat配置文件概述</span></h1><h2><span id="配置文件依赖关系"> 配置文件依赖关系</span></h2><pre><code class=" mermaid">graph LRAPP --&gt; mycat-servermycat-server --&gt; server.xml mycat-server --&gt; schema.xml --&gt; rule.xmlmycat-server --&gt; log4j2.xml --&gt; 日志文件mycat-server --&gt; DBserver</code></pre><h3><span id="serverxml"> server.xml</span></h3><ol><li>系统相关参数</li><li>用户访问权限</li><li>sql防火墙，屏蔽一些特殊的sql语句，控制访问者主机ip。</li><li>sql拦截器功能，记录特定 sql 的日志。</li></ol><h3><span id="rulexml"> rule.xml</span></h3><p>常用分片算法</p><ul><li><p>简单取模 - partitionByMod，对column直接取模</p><p>只能用在整数类型的表</p></li><li><p>哈希取模 - partitionByHashMod，对 column 先进行hashcode计算后再取模</p><p>可以用在字符串类型的表</p></li><li><p>字符串范围取模 - partitionByPrefixPattern，字符串转ASCII码后，进行累加后再对取模基数进行取模。</p><p>根据字符串的范围进行分片，比如订单号的后五位，日期的前3位，等。</p></li><li><p>分片枚举 - PartitionByFileMap， 根据列的值进行映射分表，</p><p>列的值需要有限，枚举值与数据库映射关系配置在 mapFile 中。</p></li></ul><h3><span id="schemaxml"> schema.xml</span></h3><ul><li>配置 逻辑库与物理库直接的关系</li><li>配置 逻辑库的具体分片rule</li><li>配置 物理库的连接信息</li></ul><h2><span id="mycat命令行操作"> mycat命令行操作</span></h2><p>show @@help ，查看所有命令</p><p>reload @@config，重新加载配置文件。（重新加载的时候，系统是不可用的，高峰期的时候还是需要使用滚动重启的方式）</p><p>show @@databases，显示所有物理数据库</p><p>show @@datanodes，显示所有数据节点</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mycat </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分库分表 </tag>
            
            <tag> 中间件 </tag>
            
            <tag> mycat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mycat【4】容器化</title>
      <link href="/2021/08/01/mycat/mycat%E3%80%904%E3%80%91%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
      <url>/2021/08/01/mycat/mycat%E3%80%904%E3%80%91%E5%AE%B9%E5%99%A8%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p>本章讲的是，mycat 具体实践的代码，小抄</p><span id="more"></span><hr><h1><span id="mycat容器化"> mycat容器化</span></h1><h2><span id="dockerfile"> dockerfile</span></h2><p>当前目录一览</p><figure class="highlight crmsh"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs crmsh">.<br>├── Dockerfile<br>├── mycat-conf<br>│   ├── log4j2.<span class="hljs-keyword">xml</span><br><span class="hljs-title">│   ├── rule</span>.<span class="hljs-keyword">xml</span><br><span class="hljs-title">│   ├── schema</span>.<span class="hljs-keyword">xml</span><br><span class="hljs-title">│   ├── server</span>.<span class="hljs-keyword">xml</span><br><span class="hljs-title">│   └── 此目录会覆盖 mycat</span>/conf ，简略展示<br>└── mycat-server-<span class="hljs-number">1.6</span>.<span class="hljs-number">7.5</span>-release<br>    ├── bin<br>    ├── catlet<br>    ├── conf<br>    ├── lib<br>    ├── logs<br>    └── <span class="hljs-keyword">version</span>.txt<br><br></code></pre></div></td></tr></table></figure><p>Dockerfile</p><figure class="highlight dockerfile"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> openjdk:<span class="hljs-number">8</span><br><br><br><span class="hljs-comment"># 标记mycat 版本号</span><br><span class="hljs-keyword">ENV</span> MYCAT_HOME=/app/mycat<br><br><span class="hljs-comment"># 添加 mycat - server</span><br><span class="hljs-keyword">COPY</span><span class="bash"> ./mycat-server-1.6.7.5-release <span class="hljs-variable">$MYCAT_HOME</span></span><br><br><span class="hljs-comment"># 添加 mycat 分库分表配置</span><br><span class="hljs-keyword">COPY</span><span class="bash"> ./mycat-conf <span class="hljs-variable">$MYCAT_HOME</span>/conf</span><br><br><span class="hljs-comment"># 添加 mycat -class path</span><br><span class="hljs-keyword">ENV</span> PATH=$PATH:$MYCAT_HOME/bin<br><br><span class="hljs-comment"># 启动</span><br><span class="hljs-comment"># mycat 需要使用root</span><br><span class="hljs-keyword">USER</span> root<br><span class="hljs-keyword">WORKDIR</span><span class="bash"> <span class="hljs-variable">$MYCAT_HOME</span>/bin</span><br><span class="hljs-keyword">RUN</span><span class="bash"> chmod u+x ./mycat</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">8066</span> <span class="hljs-number">9066</span><br><span class="hljs-keyword">CMD</span><span class="bash"> [<span class="hljs-string">&quot;./mycat&quot;</span>,<span class="hljs-string">&quot;console&quot;</span>]</span><br></code></pre></div></td></tr></table></figure><p>mycat 关键配置，</p><ul><li><p>rule.xml</p></li><li><p>schema.xml</p></li><li><p>server.xml</p></li></ul><p>含数据库敏感信息，详见上文。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mycat </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分库分表 </tag>
            
            <tag> 中间件 </tag>
            
            <tag> mycat </tag>
            
            <tag> dockerfile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式事务解决方案</title>
      <link href="/2021/07/31/mysql/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
      <url>/2021/07/31/mysql/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<p>这是摘要</p><span id="more"></span><hr><h2><span id="分布式事务常见解决方案"> 分布式事务常见解决方案</span></h2><h3><span id="强一致协议"> 强一致协议</span></h3><ul><li><p>两阶段提交 2PC、三阶段提交 3PC</p><img src="https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731230311.png" style="zoom:33%;"></li><li><p>落地方案：</p><ul><li><p>XA规范，是对两阶段提交的实现方案<br>资源管理器 - 事务参与者<br>事务管理器 - 事务协调者</p></li><li><p>XA规范，有十倍的性能衰减。</p><ul><li><p>有写锁，提交周期比较长</p></li><li><p>要求事务管理器，需要本地记录事务状态，机器挂了后，就不支持异地恢复。</p></li></ul></li></ul></li></ul><h3><span id="柔性事务"> 柔性事务</span></h3><ul><li>TCC 规范 （Try - Confirm - Cancel）<ul><li>尝试执行业务，预留资源<br>确认执行业务，使用Try阶段资源<br>取消执行业务，释放Try阶段预留的资源</li><li>缺点：<ul><li>业务逻辑复杂，新手不会写，老人写出来不能保证没bug。</li><li>这种东西，测试也不太好测试，线上风险太大。</li><li>业务逻辑写出bug的风险，比不同分布式事务，出问题的概率还要大得多</li></ul></li><li>TCC协议中，没有给出机器Try后，机器掉电的异常情况的处理方案，<br>本质上是个有缺陷的协议</li></ul></li><li>SAGA模型<ul><li>一个分布式事务拆分为多个本地事务<br>本地事务都有相应的执行模块和补偿模块<br>事务管理器负责在事务失败时调度执行补偿逻辑;</li><li>缺点：<ul><li>一个业务及要写正向业务逻辑，也要写出现异常的业务逻辑，工作量翻倍</li><li>即使有事务协调器，不能保证异常恢复逻辑，被精确一次执行，比如事务管理器，收到的异常执行结果为超时。</li><li>需要保证反向业务的幂等性，工作量也翻倍。</li><li>当异常回滚逻辑，第一次执行失败后，依然免不了人工介入。</li></ul></li></ul></li></ul><h3><span id="事务消息"> 事务消息</span></h3><ul><li><p>简化了分布式事务的模型，对业务友好</p></li><li><p>rocketMQ就有事务消息，可以拿来即用。</p></li></ul><h3><span id="seata-分布式事务流程"> Seata 分布式事务流程</span></h3><ul><li><strong>Seata 2PC模型</strong></li></ul><p><img src="https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731232847.png" alt="image-20210731232847753"></p><ul><li><p><strong>seata AT模型</strong></p><ul><li>介绍<ul><li>一种无侵入的分布式事务解决方案，2PC的广义实现。</li><li>源自阿里云GTS AT模式的开源版。</li></ul></li><li>核心价值<ul><li>低成本 : 编程模型不变，轻依赖不需要为分布式事务场景做特定设计。</li><li>高性能 : 一阶段提交，不阻塞;连接释放，保证整个系统的吞吐。</li><li>高可用 : 极端的异常情况下，可以暂时跳过异常事务，保证系统可用。</li></ul></li><li>实现方案</li></ul><img src="https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731233319.png" alt="image-20210731233319236" style="zoom:50%;"></li></ul><p><img src="https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731233418.png" alt="image-20210731233418204"></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分库分表 </tag>
            
            <tag> 分布式事务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分库分表策略概述</title>
      <link href="/2021/07/31/mysql/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E7%AD%96%E7%95%A5%E6%A6%82%E8%BF%B0/"/>
      <url>/2021/07/31/mysql/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E7%AD%96%E7%95%A5%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<p>本章主要讲大量数据的分库分表</p><span id="more"></span><hr><h2><span id="什么时候考虑分表"> 什么时候考虑分表</span></h2><ul><li>在线服务，单表超过1000万，考虑分表</li></ul><h2><span id="分库分表的方式"> 分库分表的方式</span></h2><h3><span id="分表方式"> 分表方式</span></h3><ul><li><p>取模：存储相对均匀，访问也均匀，用户数据一般这样分，</p></li><li><p>宽表拆成窄表，假如有一个宽表，有的列需要频繁改动，则拆出去。<br>比如 user <code>uid , nickname, img_url, userswitch</code> 其中userswitch 是一个64位Long类型，<br>描述了用户的很多开关，比如是否允许被加好友，是否允许被搜索到，是否允许xxx等<br>可以拆成 user_extra 来单拎出来，进行查询 or 修改</p></li><li><p>按时间：冷热库拆分，订单场景。</p></li></ul><h3><span id="分库的方式"> 分库的方式</span></h3><ul><li>按业务垂直分，用户库，商品库，订单库。防止某个业务把整个数据库压垮</li><li>水平分成多个库，一般伴随着分表进行，<br>比如一个表分成128个表，再分成4个库进行存储。</li></ul><h2><span id="分表最佳实践"> 分表最佳实践</span></h2><h3><span id="用户库分表"> 用户库分表</span></h3><ul><li>选择合适的分片键， 一般通过uid分片</li></ul><h3><span id="商品库分表"> 商品库分表</span></h3><ul><li>基因注入法 【todo】</li></ul><h3><span id="系统消息分表"> 系统消息分表</span></h3><ul><li>冷热数据分表<br>假如系统消息有效期为30天，按月分库。msg_1901，msg_1902，msg_1903。。。。<br>如果查询的时候30天的数据，则需要查询2个表，不舒服。<br>可用用双写的方案，当月数据也写到下月的数据表中。<br>查询的时候，则查询本月数据表，本月数据表中，自然携带上月的数据。</li></ul><h2><span id="sharding-sphere应用实践"> Sharding Sphere应用实践</span></h2><h3><span id="分库分表带来的问题"> 分库分表带来的问题</span></h3><ul><li><p>查询路由问题</p><ul><li>分表规则</li><li>写入路由</li><li>查询路由</li><li>分页查询方案</li></ul></li><li><p>Sharding Sphere 选型</p><ul><li><p>sharding sphere ，从业务进程内，对sql进行改写。</p></li><li><p>sharding proxy，代理访问数据库，使得访问变得透明。</p><table><thead><tr><th>对比项</th><th>sharding-jdbc</th><th>sharding-proxy</th></tr></thead><tbody><tr><td>数据库</td><td>任意<br>只要JDBC支持的库<br>他都支持</td><td>仅mysql</td></tr><tr><td>异构语言</td><td>仅支持java</td><td>任意语言</td></tr><tr><td>连接数</td><td>高</td><td>低</td></tr><tr><td>性能</td><td>损耗低</td><td>损耗略高</td></tr><tr><td>去中心化</td><td>是</td><td>否</td></tr><tr><td>静态入口<br>Navicat直接访问</td><td>无</td><td>有</td></tr></tbody></table></li></ul></li><li><p>最终选型，全家桶方案</p><img src="https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731215348.png" style="zoom:50%;"></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分库分表 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>innodb索引优化</title>
      <link href="/2021/07/31/mysql/innodb%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96/"/>
      <url>/2021/07/31/mysql/innodb%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p>本章主要介绍 innodb 引擎的大量数据索引优化</p><span id="more"></span><hr><h2><span id="索引原理"> 索引原理</span></h2><h3><span id="聚簇索引"> 聚簇索引</span></h3><p><img src="https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731010412.png" alt="img"></p><ul><li>数据存储在主键索引中</li><li>数据按主键顺序存储</li></ul><h3><span id="二级索引"> 二级索引</span></h3><p><img src="https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731151934.png" alt="image-20210731151934246"></p><ul><li><p>除了主键索引以外的所有，都是二级索引</p></li><li><p>叶子中，存的是主键的值</p></li><li><p>一次查询，需要经过2次的查询操作，2logN 复杂度。</p></li><li><p>主键的大小，会影响索引的大小。</p></li><li><p>对于叶子节点，存【主键值】，还是存【数据地址】的取舍：</p><p>innodb可能需要回表查询，即在聚簇索引中进一步查找对应的数据行。这样可以避免在行移动或者插入新数据时出现的页分裂问题。</p><p>MyISAM中无论是主键索引还是二级索引，索引的叶子节点存放的都是指向数据行的指针，保证可以通过索引进而查找到对应的数据行，只需要对索引进行一遍查找。但这样会存在页分裂问题。</p></li></ul><h3><span id="联合索引"> 联合索引</span></h3><p><img src="https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731153830.png" alt="image-20210731153830652"></p><ul><li>一个索引只创造1课树</li><li>假设有2列，就把量列拼接起来，(A:B) 形成一个长的组合索引</li><li>先通过A查找，找到后再通过B查找</li><li><strong>总结：</strong><ul><li>如果不是按照最左开始查找，则无法使用索引，比如本例无法直接通过B查找</li><li>如果是范围查找，则后面的列，无法使用索引。</li></ul></li></ul><h2><span id="索引优化分析"> 索引优化分析</span></h2><h3><span id="存储空间-数据量与b树的层高关系"> 存储空间 （数据量与B+树的层高关系）</span></h3><ul><li>每个 page 都有一个 level，leaf page 的 level 是 0，root page 的 level 取决于整个 B+Tree 的高度。</li><li>因为页存储有 「空洞」 现象，所以不是非常固定的</li><li>一般来说 当数据为理论值的 2/3 时， 树就开始加一层了。</li></ul><p>已知：</p><ul><li><p>Int 类型主键，每页可以存 1203 个子节点指针。</p></li><li><p>bigint 类型主键，每页可以存 900 个子节点指针。</p></li><li><p>对于最下面一层的叶子节点：</p><ul><li>单行数据为 n byte ，每个page存 (16000  / n ) 条记录<br> 假如 1 行数据 300 byte，每个page 存 (16000  / n = 50）行数据。</li></ul></li></ul><p><strong>层高计算公式 ：</strong></p><p><em><em>总行数 = （每页指针数） ^（几层）</em> 每页行数</em>*</p><p>当主键为 int (4 byte) 类型时，极限值为</p><table><thead><tr><th>高度</th><th>多少个<br>索引页<br>（非叶子）</th><th>多少个<br>数据页<br>（叶子）</th><th>每页能存<br>几个记录</th><th>得到的行数</th><th>数据大小大小</th></tr></thead><tbody><tr><td>1（0+1）</td><td>0</td><td>1</td><td>50</td><td>50</td><td>16k</td></tr><tr><td>2（1+1）</td><td>1</td><td>1203</td><td>50</td><td>6万</td><td>18MB</td></tr><tr><td>3（2+1）</td><td>1204</td><td>1,447,209</td><td>50</td><td>7亿</td><td>22G</td></tr><tr><td>4（3+1）</td><td>1,447,209</td><td>17亿</td><td>50</td><td>850亿</td><td>25T</td></tr></tbody></table><p>当主键为 bigint (8 byte) 类型时，极限值为</p><table><thead><tr><th>高度</th><th>多少个<br>索引页<br>（非叶子）</th><th>多少个<br>数据页<br>（叶子）</th><th>每页能存<br>几个记录</th><th>得到的行数</th><th>数据大小大小</th></tr></thead><tbody><tr><td>1（0+1）</td><td>0</td><td>1</td><td>50</td><td>50</td><td>16k</td></tr><tr><td>2（1+1）</td><td>1</td><td>928</td><td>50</td><td>46400</td><td>18MB</td></tr><tr><td>3（2+1）</td><td>928</td><td>861,184</td><td>50</td><td>4000万</td><td>22G</td></tr><tr><td>4（3+1）</td><td>861,184</td><td>8亿</td><td>50</td><td>40亿</td><td>25T</td></tr></tbody></table><p>参考：<a href="https://blog.jcole.us/2013/01/10/btree-index-structures-in-innodb/">https://blog.jcole.us/2013/01/10/btree-index-structures-in-innodb/</a></p><h3><span id="主键选择"> 主键选择</span></h3><ul><li><p>自增主键</p><ul><li>顺序写入，效率高</li><li>每次查询都走2级索引</li></ul></li><li><p>随机主键</p><ul><li>节点分裂，数据移动，效率比较低</li><li>有可能查询走2级索引</li></ul></li><li><p>业务主键，比如订单号，用户id，商品id，等</p><ul><li>需要保证值是递增，一般情况下使用雪花算法即可</li><li>写入，查询磁盘利用率都高，可以使用一级索引</li></ul></li><li><p>联合主键</p><ul><li>影响索引列大小，不容易维护，不建议使用</li></ul></li></ul><h3><span id="联合索引使用"> 联合索引使用</span></h3><ul><li>按索引区分度排序，区分度越高的放在前面。<br>比如主键，时间，外键，手机号，身份证号等。<br>索引区分度低的有，类型，状态等</li><li>覆盖索引，我们要查询的数据，正好在索引中，那么就不用回表了<br>比如一个索引 （id,phone,addr），在执行 <code>select phone，addr from user where id = 8;</code> 时<br>可以不用回表，直接返回结果集，又称三星索引。</li><li>索引下推，mysql 5.6推出的性能改进，减少回表的次数，本该如此，不必细聊。</li></ul><h3><span id="索引避坑指南"> 索引避坑指南</span></h3><ul><li><p>设置合理的长度</p><ul><li><p>前10个字符建索引就行，如果前10个字符都体现不出区分度，那么这个数据本身也有点问题<br></p></li><li><p>解决方案，对于区分度不大的列，再建立一个 hash 值列，通过索引（hash(addr),addr）查找就快了</p></li></ul></li><li><p>索引失效的情况</p><ul><li><p>A = XX or B=xx 索引会失效么？<br>不会失效，<br> mysql 5.1 引入了Index merge 技术，已经可以同时对 1个表使用多个索引分别扫描，1次出结果</p></li><li><p>在联合索引中使用第二列，比如（phone，id_card_num）<br>使用<code>select * from user where id_card_num= 3701xxxxxx</code> 就不走索引</p></li><li><p>隐式类型转换，不走索引<br></p><figure class="highlight plaintext"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs mysql">-- type moblie Long<br>-- 就不走索引<br>select * from user where moblie= &#x27;186123232222&#x27;<br></code></pre></div></td></tr></table></figure><p>类型转换的时候，不使用索引。<br>上线前跑一遍查询计划，看看有没有这事，这个事很容易发生，但不容易发现。</p></li><li><p>索引列包含计算，不走索引</p></li></ul>  <figure class="highlight plaintext"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs mysql">select * from user where age-20 = 30;<br>-- 没有人会这么干，如果有人这么干，必须请大家吃饭<br></code></pre></div></td></tr></table></figure><ul><li><p>索引区分度低，有时候也不走索引<br>当索引的区分度过低，比如 sex ，if_old , sell_status 列，使用sql语句<br><code>select * from user where sex=1 and phone=18678922342</code><br>通过 sex 索引查询，要频繁的回表，这时候使用索引查询，还不如直接使用全表扫描更快。<br></p></li><li><p>查询条件，覆盖所有的索引值。也不会走本列索引<br>比如，有个 age 字段，使用sql语句，<code>select * from user where age &lt; 200</code><br>的时候，因为查询语句中的条件已经全部覆盖了整个数据集。<br>所以mysql也不会使用该索引。</p></li></ul></li></ul><h3><span id="column类型最佳实践"> column类型最佳实践</span></h3><ul><li>数据库字符集使用 utf8mb4</li><li>VARCHAR 按实际需要分配长度 ，255以上，需要更多的而空间描述长度，浪费空间</li><li>文本字段建议使用 VARCHAR</li><li>时间 字段使用 long，兼容性好，要不然迁移的时候，time类型有时区概念，容易出现bug</li><li>bool字段使用tinyint</li><li>枚举字段建议使用 tinyint</li><li>交易金额 建议使用 long，存成分已足够，￥1.01存成 101</li><li>禁止使用 “%” 前导的查询</li><li>禁止在索引列进行数学运算，会导致索引失效</li></ul><h3><span id="索引类型最佳实践"> 索引类型最佳实践</span></h3><ul><li>表必须有主键，建议使用业务主键，使用雪花算法保证自增。</li><li>单张表中索引数量不超过5个</li><li>单个索引字段数不超过5个</li><li>字符串索引使用前缀索引，前缀长度不超过10个字符</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> innodb </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>innodb存储实现</title>
      <link href="/2021/07/30/mysql/innodb%E5%AD%98%E5%82%A8%E5%AE%9E%E7%8E%B0/"/>
      <url>/2021/07/30/mysql/innodb%E5%AD%98%E5%82%A8%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p>本章主要介绍 innodb 引擎的存储实现</p><span id="more"></span><hr><h2><span id="mysql-innodb-存储磁盘存储结构"> mysql innodb 存储磁盘存储结构</span></h2><p>innodb 的存储结构分为 5 级：<strong>表空间、段、簇、页、行。</strong></p><h3><span id="簇b树聚簇索引"> 簇（B+树，聚簇索引）</span></h3><p><img src="https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731010412.png" alt="img"></p><ul><li>整个树有序，结构类似于跳表。</li><li>分为非叶子节点、叶子节点</li><li>非叶子节点，存主键+下一级指针。叶子节点存主键+数据</li><li>行是有序的，根据主键排序，所以支持2分查找</li><li>数据有冗余，有未分配空间，有已删除空间。所以数据主键要保递增，减少碎片化。</li></ul><h3><span id="页page"> 页(Page)</span></h3><img src="https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210730224756.png" alt="image-20210730224756023" style="zoom:40%;"><ul><li>默认1页为16kb</li><li>页头，本页基本信息</li><li>虚记录，本页最小主键，本页最大主键。</li><li>【行】记录堆，行记录存储区，分为有效记录和已删除记录</li><li>未分配空间，页中未使用的空间</li><li>页尾，占8字节，主键存页面的校验信息</li></ul><h2><span id="mysql-innodb-内存管理"> mysql innodb 内存管理</span></h2><p>todo</p><h2><span id="mysql-innodb-事务实现原理"> mysql innodb 事务实现原理</span></h2><h3><span id="事务特性"> 事务特性：</span></h3><ul><li>A（atomicity 原子性）：全部成功，全部失败。不允许中间状态</li><li>I （isolation 隔离性）：并行事务不干扰</li><li>D（Durability 持久性）：提交事务后，数据不能丢</li><li>C（consistency 一致性）：凑数的</li></ul><h3><span id="并发问题"> 并发问题：</span></h3><ul><li>脏读（dirty read）： 读取到其他事务，没有提交的数据</li><li>不可重复读（non-repeatable read）：查询同一条数据两次，有可能结果不一样</li><li>幻读（phantom read）：select 出来的结果，可能是不存在的。<br>被其他事务插入后又删了，但中间存在期间，本事务恰好扫描到他了</li></ul><h3><span id="隔离级别"> 隔离级别：</span></h3><ul><li><p>Read Uncommitted（读取未提交内容）: 最低隔离级别，会读取到其他事务未提交的数据，</p><p>出现的问题：<strong>脏读</strong></p></li><li><p>Read Committed（读取提交内容）: 事务过程中可以读取到其他事务已提交的数据，</p><p>出现的问：<strong>不可重复读</strong></p></li><li><p>Repeatable Read（可重复读）: 每次读取相同结果集，不管其他事务是否提交，</p><p>出现的问题：<strong>幻读</strong></p></li><li><p>Serializable （串行化）: 事务排队，隔离级别最高，性能最差;</p><p>出现的问题：<strong>性能差</strong></p></li><li><p>总结：</p><ol><li>一般使用 RR （可重复读），但写事务的时候，尽量避免 select 范围修改。<br>如果有范围修改，则思考一下，有没有可能出现幻读，如果出现了是否有影响。</li><li>对于innodb，mvcc 并没有完全解决幻读问题。</li></ol></li></ul><h2><span id="innodb-mvcc"> innodb - mvcc</span></h2><h3><span id="两种查询模式"> 两种查询模式</span></h3><ul><li>当前读：永远查询某一行数据的最新的版本</li><li>读快照：假设当前事务为A，根据事务A的 trx id（事务id）总能查到，A事务开启的那一刻， <br>数据的历史版本快照。这个快照是永远不会发生改变的。</li></ul><h3><span id="可见性逻辑"> 可见性逻辑</span></h3><ul><li>trx id 指的是事务id，是一个自增的序列。id 大，证明事务发生的时间靠后</li><li>innodb 维护一个事务活跃列表，即 select * from information_schema.INNODB_TRX 查出来的数据。</li><li>可见性逻辑：<ol><li>事务开始的那一刻，查询所有当前事务。tmp_trx = [当前所有事务id]</li><li>tmp_trx_max = [时间轴最靠后的事务]，tmp_trx_min = [时间轴最靠前的事务]</li><li>搜索出来的数据，需要满足2个条件其中之一即可。<ul><li>事务id，比tmp_trx_min 的id要小（查出来的记录，在事务创建之前，就提交了）</li><li>不在事务活跃列表里面。（这个事务跑得快，已经先一步提交）</li></ul></li><li>如果不满足，则通过历史版本指针，找到该行数据的历史快照，正常使用即可</li></ol></li></ul><h2><span id="mysql-锁实现原理"> mysql 锁实现原理</span></h2><h3><span id="需要加锁的语句"> <strong>需要加锁的语句</strong></span></h3><p>select for update 、update、delete ，其他语句不用加锁。</p><h3><span id="分析锁的几个重要前提"> <strong>分析锁的几个重要前提</strong></span></h3><ul><li>索引：唯一索引 、 非唯一索引</li><li>事务隔离级别：RC 、 RR</li></ul><h3><span id="根据颗粒度划分"> <strong>根据颗粒度划分</strong></span></h3><ul><li><p>行级，锁1行</p><ul><li><p>RC下，唯一索引，非唯一索引，使用该级别锁。</p><p>RR下，唯一索引，使用该级别</p></li><li><p>作用在索引上</p></li><li><p>聚簇索引 &amp; 二级索引</p></li></ul></li><li><p>间隙，锁一部分</p><ul><li><p>RR下，唯一索引，才使用这个锁类型</p></li><li><p>索引是有序的，新的记录插入，只能插入到GAP区间内；<br>GAP锁，是计算出两条记录之间的GAP；<br>一旦锁住这个GAP。就封住了新纪录插入的可能性；<br>就能保证2次当前读返回的数据是一致的。</p></li><li><p>GAP锁的问题：查询where条件没有索引的时候，没法加GAP锁，很容易锁升级为表锁。</p></li></ul></li><li><p>表级，锁1个表</p><ul><li><strong>没有命中索引的时候，有概率锁表，概率还不小。</strong></li><li>所以，事务中，加锁的语句中的where条件一定要加索引。</li><li>一般来说，分两个步骤实现修改<ol><li>范围查询，返回主键id</li><li>根据主键id list 进行 update。</li></ol></li></ul></li></ul><h3><span id="根据类型划分"> <strong>根据类型划分</strong></span></h3><ul><li>共享锁<ul><li>读锁，可以被多个事务获取，阻止其他事务对记录的修改</li></ul></li><li>排他锁<ul><li>写锁，只能被1个事务获取，只允许获得锁的事务修改数据</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> innodb </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>生产就绪备忘清单</title>
      <link href="/2021/07/30/%E6%8A%80%E6%9C%AF%E8%A7%84%E8%8C%83/%E7%94%9F%E4%BA%A7%E5%B0%B1%E7%BB%AA%E5%A4%87%E5%BF%98%E6%B8%85%E5%8D%95/"/>
      <url>/2021/07/30/%E6%8A%80%E6%9C%AF%E8%A7%84%E8%8C%83/%E7%94%9F%E4%BA%A7%E5%B0%B1%E7%BB%AA%E5%A4%87%E5%BF%98%E6%B8%85%E5%8D%95/</url>
      
        <content type="html"><![CDATA[<p>功能完备只是起点，服务总要经过线上的打磨与历练； <br>这里有份清单标志着生产的就绪； <br>在街头，口口相传，哥哥来告诉弟弟</p><span id="more"></span><hr><h2><span id="生产就绪备忘清单"> 生产就绪备忘清单</span></h2><table><thead><tr><th>要求</th><th>自查套路</th><th>是否完成</th><th>备注</th></tr></thead><tbody><tr><td>功能完备</td><td>对照产品文档；<br>对照接口文档回顾一遍<br>大约20分钟即可</td><td></td><td></td></tr><tr><td>性能完备</td><td>预期流量是多少<br>是否需要压测，其实很多服务不需要压测<br>如果有点压力的话，可以与运维沟通加点机器<br>或者与组长提前沟通一下，说一下压力点</td><td></td><td></td></tr><tr><td>容量规划</td><td>日志产物<br>IO上传、现在产物<br>产物留存时间<br>清理计划</td><td></td><td></td></tr><tr><td>中间件迭代</td><td>中间件Schema<br>mysql、mq topic、es、hbase 是否准备完毕<br>不只要建好，更要确定此版本schema已经备份</td><td></td><td></td></tr><tr><td>数据迭代</td><td>是否需要数据迁移<br>数据迁移功能是否经过测试<br>是否有线上验证逻辑</td><td></td><td></td></tr><tr><td>兼容性考量</td><td>中间件：是否可以提前准备中间件环境<br>接口：与外部接口的交互，新旧版本支持情况<br>内部接口，是否有依赖关系，是否可以乱序上线</td><td></td><td></td></tr><tr><td>配置文件</td><td>是否是prod 配置文件，是否完备</td><td></td><td></td></tr><tr><td>日志管理</td><td>走读代码<br>关键条件分支是否添加日志<br>日志量评估，3天，10天，90天分别多大。<br>日志分级</td><td></td><td></td></tr><tr><td>健康检查接口</td><td>是否具备<br>是否与监控组件调试通过<br>是否联通容器的Heathcheck</td><td></td><td></td></tr><tr><td>调用链监控</td><td>是否接入tracer <br>traceId 是否已经打通日志</td><td></td><td></td></tr><tr><td>部署数量</td><td>多少流量，<br>多少数据量，<br>多少机器，<br>是否可以快速扩容新节点</td><td></td><td></td></tr><tr><td>高可用</td><td>是否是多节点，<br>是否需要多集群，<br>如果部分节点宕机是否继续可用</td><td></td><td></td></tr><tr><td>拓展性</td><td>是否是无状态应用<br>是否支持服务漂移<br>有状态应用需要主备同步，副本机制</td><td></td><td></td></tr><tr><td>回滚策略</td><td>确定上一个版本的tag<br>中间件schema 回滚语句准备完成<br>是否需要回滚数据</td><td></td><td></td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 技术规范 </tag>
            
            <tag> devOps </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分支规范</title>
      <link href="/2021/07/30/%E6%8A%80%E6%9C%AF%E8%A7%84%E8%8C%83/%E5%88%86%E6%94%AF%E8%A7%84%E8%8C%83/"/>
      <url>/2021/07/30/%E6%8A%80%E6%9C%AF%E8%A7%84%E8%8C%83/%E5%88%86%E6%94%AF%E8%A7%84%E8%8C%83/</url>
      
        <content type="html"><![CDATA[<p>介绍一个分支模型 - AoneFlow。<br>已经使用1年，目前没遇到坑，用起来也比较舒服，优雅。</p><span id="more"></span><hr><h2><span id="分支规范"> 分支规范</span></h2><p>AoneFlow：一种 TrunkBased 与 GitFlow  的折衷方案</p><h4><span id="三种分支类型"> 三种分支类型</span></h4><ul><li>主干分支 master tag: v1.2、 v1.3 <br>对应线上的当前代码，需要只读保护。</li><li>发布分支 release/qa1、release/qa2… 、release/ prod <br>对应测试环境、预发环境上的代码（测试环境可能有很多个，有时候需要并行测试）<br>禁止直接push，仅支持merge request 后push</li><li>特性分支 feature/001、feature/002<br>对应功能点分支。</li></ul><h4><span id="组成"> 组成</span></h4><p>一个master + N个 feature 分支 + N个 release 分支</p><h4><span id="工作流程"> 工作流程</span></h4><ol><li>开始工作前，从master 创建特性分支 feature/001，开始开发。</li><li>开发完毕后，feature/001 提交 PR 到 release/qa， 此时开发者相互CR 其他人的 PR。</li><li>CR完成后，合并所有PR，如果有冲突，重新提交无冲突的 PR，开始测试。</li><li>测试完毕后<ol><li>检查master 是否有更新，比如开发新特性的时候，master分支发生了hotfix。<br>如果有更新，则需要对 release/prod 进行回归测试。</li><li>根据master 创新新分支 release/prod , 将 release/qa 合并到 release/prod</li></ol></li><li>使用 release/prod merge 到 master <br>此时墙裂建议使用idea diff code 功能，整体看一下本次的合并，有没有额外的脏代码<br>合并后，添加 tag ，开始上线流程。</li><li>上线后，删除相关的 feature 分支，清理半年以前的tag，看日志，观察程序运行情况。</li></ol><h4><span id="核心逻辑"> 核心逻辑</span></h4><p>任何代码的改动，只能在feature 上push，其他分支的代码，如果需要响应改动<br>则通过 merge request 将变动传进来。</p><h4><span id="小痛点"> 小痛点</span></h4><ul><li>提交改动有点麻烦，每次都要在feature分支上提交后，在release分支上进行merge request</li><li>这个模式的一个痛点，当n个f分支，n个release分支的时候<br>需要记住，n个feature分支，与release 分支间的对应关系。</li></ul><h4><span id="工具"> 工具</span></h4><ul><li>阿里巴巴内部使用aone平台管理，对外发布的产品叫 <a href="https://help.aliyun.com/document_detail/153762.html?spm=5176.168087.J_7469444330.4.91376942pV1EvU">云效平台</a></li><li>有赞qa平台，公交车发布系统，也借鉴了aoneFlow的思路<a href="https://tech.youzan.com/team/">3.4 公交车系统</a></li></ul><h4><span id="参考介绍"> 参考介绍：</span></h4><ul><li><a href="https://blog.csdn.net/bbcckkl/article/details/111087267">项目版本管理的最佳实践：飞流Flow（阿里AoneFlow）篇</a></li><li><a href="https://blog.csdn.net/liumingzhe1/article/details/105287150">Git-flow分支管理与Aone-flow分支管理对比</a></li><li><a href="https://www.infoq.cn/article/EaC4c6yiJrzZ_Gtaf9Ne">阿里巴巴如何管理代码分支？ </a></li><li><a href="http://bos.itdks.com/7b7b1baa2f1244b8b3c2b3ae26de3eea.pdf">阿里巴巴在DevOps实践中的创新和思考-ppt </a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计 </tag>
            
            <tag> 技术规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>API设计规范</title>
      <link href="/2021/07/30/%E6%8A%80%E6%9C%AF%E8%A7%84%E8%8C%83/API%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83/"/>
      <url>/2021/07/30/%E6%8A%80%E6%9C%AF%E8%A7%84%E8%8C%83/API%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83/</url>
      
        <content type="html"><![CDATA[<p>http设计规范，设计接口后，可以对照自查表自省一下。</p><span id="more"></span><hr><h2><span id="api设计自查表"> API设计自查表</span></h2><table><thead><tr><th style="text-align:left">考虑点</th><th>结论</th></tr></thead><tbody><tr><td style="text-align:left">接口命名</td><td></td></tr><tr><td style="text-align:left">入参</td><td></td></tr><tr><td style="text-align:left">出参</td><td></td></tr><tr><td style="text-align:left">header</td><td></td></tr><tr><td style="text-align:left">包装结构体</td><td></td></tr><tr><td style="text-align:left">版本</td><td></td></tr><tr><td style="text-align:left">保障级别 （对内服务 or 对外服务 ｜ 使用人群）</td><td></td></tr><tr><td style="text-align:left">是否需要黑白名单，哪个位置加</td><td></td></tr><tr><td style="text-align:left">是否需要幂等，以及实现方案</td><td></td></tr><tr><td style="text-align:left">是否需要异步，以及实现方案</td><td></td></tr></tbody></table><hr><h2><span id="详细解释"> 详细解释</span></h2><h3><span id="标准接口命名"> 标准接口命名</span></h3><ul><li><p>范例：<br><code>xxx/user/p0/v1/getuserInfo</code><br>业务线 / 所属服务 / 保护级别 / 版本 / getuserInfo</p></li><li><p>禁止，PathVariable，不好管理，性能也有点问题<br>例如：/user/{user_id}</p></li><li><p>禁止，除了 get、post 以外的method，网关不好管理</p></li><li><p><strong>保护级别</strong></p><ul><li>p0: 主流程接口，对外服务核心流程，一般此类接口挂了，用户就会发现系统有问题。<br>需要全力保障的接口</li><li>p1: 非必要业务接口，一般是非核心查询接口，这类接口挂了，用户不容易察觉，<br>网关可以进行接口限流，根据user level 接口限流，也可以拿这类接口开刀。</li><li>p2: 信息采集类接口，可以不用保证可用性，后端也永远返回成功，<br>服务资源不足时候，网关可以直接下掉他们。</li></ul></li><li><p>版本号</p><ul><li>使用v1、v2即可</li></ul></li></ul><h3><span id="header"> header</span></h3><ul><li><p>jwt</p></li><li><p>业务上下文，采集使用</p><p>如 user_id，client_id，client_type，biz，version，user_level，addr 等</p><p>按需添加</p></li><li><p>调用链，trace_id，span_id，</p><p>一般由工具生成。</p></li></ul><h3><span id="入参"> 入参</span></h3><ul><li><p>对外服务公共参数</p><ul><li>防篡改签名</li><li>加token</li></ul></li><li><p>对内服务公共参数</p><ul><li>user_id</li><li>biz_id</li><li>service_id</li></ul></li></ul><h3><span id="出参"> 出参</span></h3><ul><li><p>类型</p><p>强制使用 application/json 类型，尽量为字符串类型。</p><p>避免返回Long。</p></li><li><p>返回码</p><p>业务异常、系统异常要分开。<br>业务异常保证无歧义，系统异常返回码为99999，降级使用。<br>确保多重状态，有不同的返回码，<br>例如，有一个接口叫&quot;收单接口&quot;，其内部调用&quot;下单&quot;接口。<br>收单服务正常的时候，下单接口可能返回失败。<br>设计接口结构时，状态码不能有歧义，“收单正常，下单失败” 与 “收单失败”  返回不同的状态码</p></li><li><p>包装结构</p><p>错误返回：<code>&#123; code, msg, trace_id &#125;</code><br>正常返回：<code>&#123; code, msg, result: &#123;&#125; &#125;</code> <br>分页返回：<code>&#123; code, msg, result: &#123; recordList:[], page_info:&#123;&#125; &#125; &#125;</code><br><strong>result 不允许为数组，默认为 空 {}，在java中使用 emptyMap 常量</strong></p></li></ul><h3><span id="实现幂等的策略"> 实现幂等的策略</span></h3><ul><li><p>唯一id + 时间字段。通过时间过滤后，使用trans_id 避免重复 （最通用的实现）</p><p>可以加前置 缓存队列 ，进行专门的去重。</p></li><li><p>新增类接口，加唯一索引。（低并发下，实现最简单）</p></li><li><p>乐观锁字段。（效率最高，但大量并发时需要避免）</p></li><li><p>服务端发放提交票据，（两次交互，费时费力，不推荐）</p></li><li><p>状态机幂等， <code>set order_status = [done]</code> 天生幂等</p></li></ul><p>效率优先：乐观锁 &gt; 唯一约束 &gt; 唯一索引</p><h3><span id="异步策略"> 异步策略</span></h3><p>例如<strong>上传接口</strong></p><ul><li>同步</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> SyncUploadResponse <span class="hljs-title">syncUpload</span><span class="hljs-params">(SyncUploadRequest request)</span> </span>&#123;<br>  SyncUploadResponse response = <span class="hljs-keyword">new</span> SyncUploadResponse();<br>  response.setDownloadUrl(uploadFile(request.getFile()));<br>  response.setThumbnailDownloadUrl(uploadThumbnailFile(request.getFile()));<br>  <span class="hljs-keyword">return</span> response;<br>&#125;<br></code></pre></div></td></tr></table></figure><ul><li>异步上传，立即返回一个任务id，客户端根据任务id轮询结果。</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//在接口实现上，我们同样把上传任务提交到线程池处理，但是并不会同步等待任务完成，而是完成后把结果写入一个 HashMap，任务查询接口通过查询这个 HashMap 来获得文件 的 URL</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">asyncDemo</span> </span>&#123;<br><br>    <span class="hljs-comment">//计数器，作为上传任务的ID</span><br>    <span class="hljs-keyword">private</span> AtomicInteger atomicInteger = <span class="hljs-keyword">new</span> AtomicInteger(<span class="hljs-number">0</span>);<br>    <span class="hljs-comment">//暂存上传操作的结果，生产代码需要考虑数据持久化</span><br>    <span class="hljs-keyword">private</span> ConcurrentHashMap&lt;String, SyncQueryUploadTaskResponse&gt; downloadUrl = <span class="hljs-keyword">new</span> ConcurrentHashMap&lt;&gt;();<br><br>    <span class="hljs-comment">// 立即返回任务id</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> AsyncUploadResponse <span class="hljs-title">asyncUpload</span><span class="hljs-params">(AsyncUploadRequest request)</span> </span>&#123;<br>        AsyncUploadResponse response = <span class="hljs-keyword">new</span> AsyncUploadResponse();<br>        <span class="hljs-comment">//生成唯一的上传任务ID</span><br>        String taskId = <span class="hljs-string">&quot;upload&quot;</span> + atomicInteger.incrementAndGet<br>        <span class="hljs-comment">//异步上传操作只返回任务ID</span><br>        response.setTaskId(taskId);<br>        <span class="hljs-comment">//提交上传原始文件操作到线程池异步处理</span><br>        threadPool.execute(() -&gt; &#123;<br>            String url = uploadFile(request.getFile());<br>            <span class="hljs-comment">//如果ConcurrentHashMap不包含Key，则初始化一个SyncQueryUploadTaskResponse</span><br>            downloadUrl.computeIfAbsent(taskId,<br>                    id -&gt; <span class="hljs-keyword">new</span> SyncQueryUploadTaskResponse(id)).setDownloadUrl(url);<br>        &#125;);<br><br>        <span class="hljs-comment">//提交上传缩略图操作到线程池异步处理</span><br>        threadPool.execute(() -&gt; &#123;<br>            String url = uploadThumbnailFile(request.getFile());<br>            downloadUrl.computeIfAbsent(taskId,<br>                    id -&gt; <span class="hljs-keyword">new</span> SyncQueryUploadTaskResponse(id)).setThumbnailDownloadUrl(url);<br>        &#125;);<br>        <span class="hljs-keyword">return</span> response;<br>    &#125;<br><br></code></pre></div></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计 </tag>
            
            <tag> 技术规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql开发规范</title>
      <link href="/2021/07/27/%E6%8A%80%E6%9C%AF%E8%A7%84%E8%8C%83/mysql%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/"/>
      <url>/2021/07/27/%E6%8A%80%E6%9C%AF%E8%A7%84%E8%8C%83/mysql%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/</url>
      
        <content type="html"><![CDATA[<p>http设计规范，设计接口后，可以对照自查表自省一下。</p><span id="more"></span><hr><h2><span id="建表规范"> <strong>建表规范</strong></span></h2><ol><li>默认使用使用innoDB 引擎，字符集 utf8mb4</li><li>表名称规范<br><code>[biz]_xxxx_[app|mis]_conf</code> : 在线、离线服务配置。 <br><code>[biz]_xxxx_record</code> : 数据表，最高优先级。<br><code>[biz]_xxxx_[app|mis]log</code> : 日志表，低优先级</li><li>所有字段 NOT NULL ，优先设置 unsigned，小数设置为decimal，金额存成分，时间设置为datatime</li><li>字段最大长度，保存克制，防止建索引时空间不够。</li><li>字段长度大于1024需要拆分表，使用text， 主表上存拆分表id。</li><li>表示 “是否” 字段，一律使用 if_xxx 的方式命名，数据类型是unsigned tinyint</li><li>日增10万，年增5000万，id使用bigint，雪花算法。其余情况使用integer自增主键</li><li>字段顺序依次为：主键、业务主键、状态、各种外键、各种分类、具体props、base属性… <br>正确示例：id，order_id，order_status，product_id，user_id，order_time</li><li>保留名称，show、update、desc、status、range、match、delayed</li><li>推荐：单表最大长度小于2000万，单行长度小于16Kb，单表小于2g</li></ol><h2><span id="索引规范"> <strong>索引规范</strong></span></h2><ol><li>联合索引的字段数目不能超过5，单表索引数量也不能超过5，索引设计遵循B+ Tree最左前匹配原则</li><li>对一个VARCHAR(N)列创建索引时，通常取其50%（甚至更小）左右长度创建前缀索引就足以满足80%以上的查询需求了，没必要创建整列的全长度索引</li><li>根据业务命名空间的顺序构造联合索引，比如 productId/userId/serviceId/time/xxx</li><li>order by ， group by 的字段需要建立索引，尽量不使用groupby，orderby 使用java进程完成此操作</li><li>业务上的全局唯一字段，需要建立唯一索引</li><li>事物中，如 SELECT * FROM yes WHERE name =‘yes’ FOR UPDATE; <br>通过等普通条件判断【name = xxx】进行筛选加锁时，则该列（name）需要加索引。否则容易锁表。</li><li>索引是要建在尽量不改动的字段上，频繁的变动索引列，对系统压力较大</li></ol><h2><span id="sql开发规范"> <strong>SQL开发规范</strong></span></h2><ol><li><p>对于 java 程序，只能使用 sql 模板查询，不允许使用各类动态sql生成器。</p></li><li><p>强烈推荐：只使用 mybatis_code_helper_pro 生成 xml sql 语句。</p></li><li><p>对外在线接口：<br>使用短sql，禁止三个表 join，禁止 where 子句，禁止 sql 函数。<br>对外接口尽量避免复杂查询，查询首先保证拓展性。</p></li><li><p>推荐：使用mysql执行计划验收sql语句，注意索引的有序性，尽量使用覆盖索引。</p></li><li><p>事务避免本类调用，使用hutool，SpringUtil获取事务方法。<br>直接使用传统 commit 指令也是不错的选择。</p></li><li><p>超过10万行数据，首先确定分页的必要性；能否转换为下拉查询，或时间查询。<br>必须精确分页的话，查询使用 inner join</p><figure class="highlight sql"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> tables <span class="hljs-keyword">inner</span> <span class="hljs-keyword">join</span><br>( <span class="hljs-keyword">select</span> id <span class="hljs-keyword">from</span> tables <span class="hljs-keyword">where</span> [条件]  <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> xxx limie <span class="hljs-number">10000</span>,<span class="hljs-number">10</span> )<br><span class="hljs-keyword">using</span> id;<br></code></pre></div></td></tr></table></figure></li></ol><h2><span id="分库分表后查询规范"> <strong>分库分表后查询规范</strong></span></h2><ul><li>禁用语句</li></ul><ol><li>分表后尽量只查询，或者根据 id update，避免范围修改，严禁莽撞的跨区修改。</li><li>禁止，子查询，group by，order by</li><li>禁止，悲观锁，使用Redisson替代数据库悲观锁（尽量使用无锁方法处理业务逻辑）。</li><li>禁止，update sharding-key。update 分片键后可能会导致后面的查询找不到数据。</li><li>禁止，跨区 update 、delete [order by] limit 。 mycat会在多个节点执行 limit语句，造成过多删除。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计 </tag>
            
            <tag> 技术规范 </tag>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
